{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "The SAP HANA Python Client API for machine learning algorithms (Python Client API for ML) provides a set of client-side Python functions for accessing and querying SAP HANA data, and a set of functions for developing machine learning models.\n",
    "\n",
    "The Python Client API for ML consists of two main parts:\n",
    "\n",
    "<li>A set of machine learning APIs for different algorithms.</li>\n",
    "<li>The SAP HANA dataframe, which provides a set of methods for analyzing data in SAP HANA without bringing that data to the client.</li>\n",
    "\n",
    "This library uses the SAP HANA Python driver (hdbcli) to connect to and access SAP HANA.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"images/highlevel_overview2_new.png\" title=\"Python API Overview\" style=\"float:left;\" width=\"300\" height=\"50\" />\n",
    "<br>\n",
    "A dataframe represents a table (or any SQL statement).  Most operations on a dataframe are designed to not bring data back from the database unless explicitly asked for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml import dataframe\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup connection and data sets\n",
    "Let us load some data into a HANA table.  The data is loaded into 4 tables - full set, test set, training set, and the validation set:DBM2_RFULL_TBL, DBM2_RTEST_TBL, DBM2_RTRAINING_TBL, DBM2_RVALIDATION_TBL.\n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. More information regarding the data set is at https://archive.ics.uci.edu/ml/datasets/bank+marketing#.\n",
    "\n",
    "To do that, a connection is created and passed to the loader.  There is a config file, <b>config/e2edata.ini</b> that controls the connection parameters.  Please edit it to point to your hana instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.utility import DataSets, Settings\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\n",
    "connection_context = dataframe.ConnectionContext(url, port, user, pwd)\n",
    "full_df, training_df, validation_df, test_df = DataSets.load_bank_data(connection_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple DataFrame\n",
    "<table align=\"left\"><tr><td>\n",
    "</td><td><img src=\"images/Dataframes_1.png\" style=\"float:left;\" width=\"600\" height=\"400\" /></td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = training_df\n",
    "# Alternatively, it could be any SELECT\n",
    "print(dataset1.select_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Operations\n",
    "#### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset1.drop_duplicates()\n",
    "print(dataset2.select_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = dataset2.drop([\"LABEL\"])\n",
    "print(dataset3.select_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take null values and substitute with a specific value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = dataset2.fillna(25, [\"AGE\"])\n",
    "print(dataset4.select_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_null = dataframe.create_dataframe_from_pandas(connection_context=connection_context,\n",
    "                                                      pandas_df=pd.DataFrame({\"ID\": [1,2,5],\n",
    "                                                                              \"ID2\": [1,None,5],\n",
    "                                                                              \"V3\": [2,3,4],\n",
    "                                                                              \"V4\": [3,3,3],\n",
    "                                                                              \"V5\": ['a', None, 'b']}),\n",
    "                                                      table_name=\"#tt_null\",\n",
    "                                                      force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_null.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_null.fillna(0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_null.fillna('').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_null.fillna('').fillna(0).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring data to client\n",
    "#### Fetch 5 rows into client as a <b>Pandas Dataframe</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1 = dataset4.head(5).collect()\n",
    "print(type(pd1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "<img src=\"images/Projection.png\" style=\"float:left;\" width=\"150\" height=\"750\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp = dataset4.select(\"ID\", \"AGE\", \"JOB\", ('\"AGE\"*2', \"TWICE_AGE\"))\n",
    "dsp.head(5).collect()  # collect() brings data to the client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.select_statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "<img src=\"images/Filter.png\" style=\"float:left;\" width=\"200\" height=\"100\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset4.filter('AGE > 60').head(10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.filter('AGE > 60').select_statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "<img src=\"images/Sort.png\" style=\"float:left;\" width=\"200\" height=\"100\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.filter('AGE>60').sort(['AGE']).head(2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Joins\n",
    "<img src=\"images/Join.png\" style=\"float:left;\" width=\"300\" height=\"200\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = '{}.\"ID\"={}.\"ID\"'.format(dataset4.quoted_name, dataset2.quoted_name)\n",
    "dataset5 = dataset4.join(dataset2, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5.head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = dataframe.create_dataframe_from_pandas(connection_context=connection_context,\n",
    "                                             pandas_df=pd.DataFrame({\"ID\": [1,2,3],\n",
    "                                                                     \"ID2\": [1,2,3],\n",
    "                                                                     \"V1\": [2,3,4]}),\n",
    "                                             table_name=\"#tt1\",\n",
    "                                             force=True)\n",
    "df2 = dataframe.create_dataframe_from_pandas(connection_context=connection_context,\n",
    "                                             pandas_df=pd.DataFrame({\"ID\": [1,2],\n",
    "                                                                     \"ID2\": [1,2],\n",
    "                                                                     \"V2\": [2,3]}),\n",
    "                                             table_name=\"#tt2\",\n",
    "                                             force=True)\n",
    "df3 = dataframe.create_dataframe_from_pandas(connection_context=connection_context,\n",
    "                                             pandas_df=pd.DataFrame({\"ID\": [1,2,5],\n",
    "                                                                     \"ID2\": [1,2,5],\n",
    "                                                                     \"V3\": [2,3,4],\n",
    "                                                                     \"V4\": [3,3,3],\n",
    "                                                                     \"V5\": ['a','a','b']}),\n",
    "                                             table_name=\"#tt3\",\n",
    "                                             force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1.set_index(\"ID\"), df2.set_index(\"ID\"), df3.set_index(\"ID\")]\n",
    "print(dfs[0].join(dfs[1:]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1.set_index([\"ID\", \"ID2\"]), df2.set_index([\"ID\", \"ID2\"]), df3.set_index([\"ID\", \"ID2\"])]\n",
    "print(dfs[0].join(dfs[1:]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[0].union([dfs[0], dfs[0]]).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.cast({\"AGE\": \"BIGINT\", \"JOB\": \"NVARCHAR(50)\"}).get_table_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_index().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take min, max, sum, median, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select(\"V1\").min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.value_counts().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = None\n",
    "if subset is None:\n",
    "    subset = df3.columns\n",
    "count_df = []\n",
    "id_df = []\n",
    "for col in subset:\n",
    "    id_df.append(df3.select(col).rename_columns({col: \"VALUES\"}).cast(\"VALUES\", 'NVARCHAR(255)'))\n",
    "    count_df.append(df3.agg([(\"count\", col, \"NUM_{}\".format(col))], group_by=col).set_index(col))\n",
    "idf = id_df[0].union(id_df[1:]).distinct().set_index(\"VALUES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.head(1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing a dataframe\n",
    "<img src=\"images/Describe.png\" style=\"float:left;\" width=\"300\" height=\"200\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.describe().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.head(10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.save(\"#MYTEST2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8 = connection_context.table(\"#MYTEST2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8.head(10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8.pivot_table(values='EMP_VAR_RATE', index='ID', columns='EDUCATION', aggfunc='avg').head(10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.create_dataframe_from_pandas(connection_context, dataset8.head(10).collect(), 'MYTEST3', replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_context.table(\"MYTEST3\").head(10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "split_df = \\\n",
    "dataframe.create_dataframe_from_pandas(connection_context,\n",
    "                                       pandas_df=pd.DataFrame({\"ID\": [1,2],\n",
    "                                                               \"COL\": ['1,2,3', '3,4,4']}),\n",
    "                                       table_name=\"#split_test\",\n",
    "                                       force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = split_df.split_column(column=\"COL\", separator=\",\", new_column_names=[\"COL1\", \"COL2\", \"COL3\"])\n",
    "new_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.concat_columns(columns=[\"COL1\", \"COL2\", \"COL3\"], separator=\",\").collect()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e8e26eb492012ce43ec3ea98c3fc2503d5495ecd40107dd94395e1e0d860e85"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
