{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiencing HANA ML Unified Report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UnifiedClassification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pima Indians Diabetes Dataset\n",
    "\n",
    "Original data comes from National Institute of Diabetes and Digestive and Kidney Diseases. The collected dataset is aiming at, based on certain diagnostic measurements, diagnostically predicting whether or not a patient has diabetes. In particular, patients contained in the dataset are females of Pima Indian heritage, all above the age of 20. Dataset is form Kaggle, for tutorials use only.\n",
    "\n",
    "The dataset contains the following diagnositic <b>attributes</b>:<br>\n",
    "$\\rhd$ \"PREGNANCIES\" - Number of times pregnant,<br>\n",
    "$\\rhd$ \"GLUCOSE\" - Plasma glucose concentration a 2 hours in an oral glucose tolerance test,<br>\n",
    "$\\rhd$ \"BLOODPRESSURE\" -  Diastolic blood pressure (mm Hg),<br>\n",
    "$\\rhd$ \"SKINTHICKNESS\" -  Triceps skin fold thickness (mm),<br>\n",
    "$\\rhd$ \"INSULIN\" - 2-Hour serum insulin (mu U/ml),<br>\n",
    "$\\rhd$ \"BMI\" - Body mass index $(\\text{weight in kg})/(\\text{height in m})^2$,<br>\n",
    "$\\rhd$ \"PEDIGREE\" - Diabetes pedigree function,<br>\n",
    "$\\rhd$ \"AGE\" -  Age (years),<br>\n",
    "$\\rhd$ \"CLASS\" - Class variable (0 or 1) 268 of 768 are 1(diabetes), the others are 0(non-diabetes).\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import hana_ml\r\n",
    "from hana_ml import dataframe\r\n",
    "from hana_ml.algorithms.pal import metrics\r\n",
    "from hana_ml.algorithms.pal.unified_classification import UnifiedClassification\r\n",
    "from hana_ml.algorithms.pal.unified_regression import UnifiedRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data\n",
    "\n",
    "The data is loaded into 3 tables - full set, training-validation set, and test set as follows:\n",
    "\n",
    "<li> PIMA_INDIANS_DIABETES_TBL</li>\n",
    "<li> PIMA_INDIANS_DIABETES_TRAIN_VALID_TBL</li>\n",
    "<li> PIMA_INDIANS_DIABETES_TEST_TBL</li>\n",
    "\n",
    "To do that, a connection is created and passed to the loader.\n",
    "\n",
    "There is a config file, <b>config/e2edata.ini</b> that controls the connection parameters and whether or not to reload the data from scratch. In case the data is already loaded, there would be no need to load the data. A sample section is below. If the config parameter, reload_data is true then the tables for test, training and validation are (re-)created and data inserted into them.\n",
    "\n",
    "#########################<br>\n",
    "[hana]<br>\n",
    "url=host.sjc.sap.corp<br>\n",
    "user=username<br>\n",
    "passwd=userpassword<br>\n",
    "port=3xx15<br>\n",
    "#########################<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.utility import DataSets, Settings\r\n",
    "import plotting_utils\r\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\r\n",
    "\r\n",
    "connection_context = dataframe.ConnectionContext(url, port, user, pwd)\r\n",
    "full_set, diabetes_train, diabetes_test, _ = DataSets.load_diabetes_data(connection_context)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us look at the number of rows in each dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Number of rows in training set: {}'.format(diabetes_train.count()))\r\n",
    "print('Number of rows in testing set: {}'.format(diabetes_test.count()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us look at columns of the dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(diabetes_train.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us also look some (in this example, the top 6) rows of the dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "diabetes_train.head(6).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also check the data type of all columns:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "diabetes_train.dtypes()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have a 'CLASS' column in the dataset, let us check how many classes are contained in this dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "diabetes_train.distinct('CLASS').collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two classes are available, assuring that this is a binary classification problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Model Creation & Model Selection\n",
    "The lines below show the ease with which classification can be done.\n",
    "\n",
    "Set up the label column, use default feature set and create the model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.model_selection import GridSearchCV\r\n",
    "from hana_ml.algorithms.pal.model_selection import RandomSearchCV\r\n",
    "hgc2 = UnifiedClassification('HybridGradientBoostingTree')\r\n",
    "\r\n",
    "gscv = GridSearchCV(estimator=hgc2, \r\n",
    "                    param_grid={'learning_rate': [0.1, 0.4, 0.7, 1],\r\n",
    "                                'n_estimators': [4, 6, 8, 10],\r\n",
    "                                'split_threshold': [0.1, 0.4, 0.7, 1]},\r\n",
    "                    train_control=dict(fold_num=5,\r\n",
    "                                       resampling_method='cv',\r\n",
    "                                       random_state=1,\r\n",
    "                                       ref_metric=['auc']),\r\n",
    "                    scoring='error_rate')\r\n",
    "gscv.fit(data=diabetes_train, key= 'ID',\r\n",
    "         label='CLASS',\r\n",
    "         partition_method='stratified',\r\n",
    "         partition_random_state=1,\r\n",
    "         stratified_column='CLASS',\r\n",
    "         build_report=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.visualizers.unified_report import UnifiedReport"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "UnifiedReport(diabetes_train).build().display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification Report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "UnifiedReport(gscv.estimator).display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression Report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dt_params = dict(model_format = 'pmml',\r\n",
    "                 allow_missing_dependent = True,\r\n",
    "                 percentage = 1,\r\n",
    "                 use_surrogate = True,\r\n",
    "                 split_threshold = 1e-5,\r\n",
    "                 min_records_of_parent = 2,\r\n",
    "                 min_records_of_leaf = 1,\r\n",
    "                 thread_ratio = 0.5,\r\n",
    "                 evaluation_metric='rmse')\r\n",
    "udtr = UnifiedRegression(func = 'DecisionTree', **dt_params)\r\n",
    "#udtr.fit(data = self.data_dt, partition_method = 'random',\r\n",
    "#         partition_random_state=2, output_partition_result = True)\r\n",
    "\r\n",
    "gscv = GridSearchCV(estimator=udtr, \r\n",
    "                    param_grid={'split_threshold': [0.1, 0.4, 0.7, 1]},\r\n",
    "                    train_control=dict(fold_num=5,\r\n",
    "                                       resampling_method='cv',\r\n",
    "                                       random_state=1),\r\n",
    "                    scoring='rmse')\r\n",
    "gscv.fit(data=diabetes_train, key= 'ID',\r\n",
    "         label='CLASS',\r\n",
    "         partition_method='random',\r\n",
    "         partition_random_state=1,\r\n",
    "         build_report=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "UnifiedReport(gscv.estimator).display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "connection_context.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "9e8e26eb492012ce43ec3ea98c3fc2503d5495ecd40107dd94395e1e0d860e85"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}