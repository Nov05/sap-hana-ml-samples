{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.dataframe import ConnectionContext\n",
    "from data_load_utils import DataSets, Settings\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\n",
    "connection_context = ConnectionContext(url, port, user, pwd)\n",
    "connection_context.get_current_schema()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_samples = 100\n",
    "df = pd.DataFrame(np.random.randn(n_samples,2))\n",
    "df.columns = ['X1', 'X2']\n",
    "df_clustering = create_dataframe_from_pandas(connection_context=connection_context, pandas_df=df, table_name='RAM_TBL', force=True, replace=True)\n",
    "df_clustering = df_clustering.add_id('ID')\n",
    "\n",
    "n_samples = 10\n",
    "df2 = pd.DataFrame(np.random.randn(n_samples,2))\n",
    "df2.columns = ['X1', 'X2']\n",
    "df_predict = create_dataframe_from_pandas(connection_context=connection_context, pandas_df=df2, table_name='RAM_PREDICT_TBL', force=True, replace=True)\n",
    "df_predict = df_predict.add_id('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FUNCTION', None, None, 'AHC'), ('N_CLUSTERS', 4, None, None), ('AFFINITY', 10, None, None), ('LINKAGE', 4, None, None), ('THREAD_RATIO', None, None, None), ('DISTANCE_DIMENSION', None, 3, None), ('NORMALIZATION', 0, None, None), ('CATEGORY_WEIGHTS', None, 0.1, None), ('CATEGORICAL_VARIABLE', None, None, 'X3')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:hana_ml.algorithms.pal.unified_clustering:AgglomerateHierarchicalClustering does not provide predict function!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "AgglomerateHierarchicalClustering does not provide predict function!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8507ff4e585d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m                    pd.Series(data=[1, 1, 1, 1, 1, 2], name = 'CLUSTER_ID'))\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0muahc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ahc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'POINT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\i319826\\documents\\hanamlapi\\src\\hana_ml\\algorithms\\pal\\sqlgen.py\u001b[0m in \u001b[0;36mfunction_with_sql_tracing\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_tracer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_sql_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunction_with_sql_tracing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i319826\\documents\\hanamlapi\\src\\hana_ml\\algorithms\\pal\\unified_clustering.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, key, features, model)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"AgglomerateHierarchicalClustering does not provide predict function!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[0mtype_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'link'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: AgglomerateHierarchicalClustering does not provide predict function!"
     ]
    }
   ],
   "source": [
    "from hana_ml.dataframe import ConnectionContext\n",
    "from data_load_utils import DataSets, Settings\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\n",
    "connection_context = ConnectionContext(url, port, user, pwd)\n",
    "connection_context.get_current_schema()\n",
    "\n",
    "import unittest\n",
    "from hana_ml.algorithms.pal.unified_clustering import UnifiedClustering\n",
    "from hana_ml.model_storage import ModelStorage\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal, assert_series_equal\n",
    "import numpy as np\n",
    "data_ahc=connection_context.table('DATA_UNICU_AHC_TBL')\n",
    "\n",
    "ahc_params = dict(\n",
    "         n_clusters=4,\n",
    "         affinity='Gower',\n",
    "         linkage='weighted average',\n",
    "         thread_ratio=None,\n",
    "         distance_dimension=3,\n",
    "         normalization=0,\n",
    "         category_weights=0.1)\n",
    "uahc = UnifiedClustering(func = 'AgglomerateHierarchicalClustering', **ahc_params)\n",
    "uahc.fit(data_ahc, key='POINT', categorical_variable=['X3'])\n",
    "\n",
    "assert_series_equal(uahc.labels_.head(6).collect()['CLUSTER_ID'],\n",
    "                   pd.Series(data=[1, 1, 1, 1, 1, 2], name = 'CLUSTER_ID'))\n",
    "\n",
    "uahc.predict(data_ahc, key='POINT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FUNCTION', None, None, 'DBSCAN'), ('METRIC', 1, None, None), ('THREAD_RATIO', None, 0.2, None), ('AUTO_PARAM', None, None, 'true')]\n"
     ]
    }
   ],
   "source": [
    "from hana_ml.dataframe import ConnectionContext\n",
    "from data_load_utils import DataSets, Settings\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\n",
    "connection_context = ConnectionContext(url, port, user, pwd)\n",
    "connection_context.get_current_schema()\n",
    "\n",
    "import unittest\n",
    "from hana_ml.algorithms.pal.unified_clustering import UnifiedClustering\n",
    "from hana_ml.model_storage import ModelStorage\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal, assert_series_equal\n",
    "import numpy as np\n",
    "data_dbscan=connection_context.table('DATA_UNICU_DBSCAN_TBL')\n",
    "data_dbscan_predict=connection_context.table('DATA_UNICU_DBSCAN_PREDICT_TBL')\n",
    "\n",
    "dbscan_params = dict(metric='manhattan', thread_ratio=0.2)\n",
    "udbscan = UnifiedClustering(func = 'DBSCAN', **dbscan_params)\n",
    "udbscan.fit(data_dbscan, key='ID', features=['V1', 'V2', 'V3'])\n",
    "\n",
    "assert_series_equal(udbscan.labels_.head(15).collect()['CLUSTER_ID'],\n",
    "                    pd.Series(data=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], name = 'CLUSTER_ID'))\n",
    "               \n",
    "result = udbscan.predict(data_dbscan_predict, key='ID' )\n",
    "expected_result = pd.DataFrame(data={'ID':[1, 2, 3, 4, 5], 'CLUSTER_ID':[0, 0, -1, 1, -1], 'DISTANCE':[0, 2.21, 3, 0.05000000000000071, 3.59]})\n",
    "assert_frame_equal(result.collect().set_index('ID'),\n",
    "                   expected_result.set_index('ID'), check_like=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FUNCTION', None, None, 'GMM'), ('INIT_MODE', 0, None, None), ('COVARIANCE_TYPE', 0, None, None), ('SHARED_COVARIANCE', False, None, None), ('MAX_ITER', 500, None, None), ('ERROR_TOL', None, 0.001, None), ('THREAD_RATIO', None, 0.5, None), ('SEED', 1, None, None), ('INITIALIZE_PARAMETER', None, None, '2')]\n",
      "   ROW_INDEX  PART_INDEX                                      MODEL_CONTENT\n",
      "0          0          -1  {\"Algorithm\":\"GMM\",\"Metadata\":{\"DataProcessor\"...\n",
      "1          1           0  {\"GaussModel\":{\"covariance\":[0.000148222222222...\n",
      "2          2           1  {\"GaussModel\":{\"covariance\":[0.000148222222222...\n",
      "   ROW_INDEX  PART_INDEX                                      MODEL_CONTENT\n",
      "0          0          -1  {\"Algorithm\":\"GMM\",\"Metadata\":{\"DataProcessor\"...\n",
      "1          1           0  {\"GaussModel\":{\"covariance\":[0.000148222222222...\n",
      "2          2           1  {\"GaussModel\":{\"covariance\":[0.000148222222222...\n",
      "     ID  CLUSTER_ID  DISTANCE\n",
      "0    99           0       1.0\n",
      "1   100           0       1.0\n",
      "2   101           0       1.0\n",
      "3   102           0       0.0\n",
      "4   103           0       0.0\n",
      "5   104           0       0.0\n",
      "6    99           1       0.0\n",
      "7   100           1       0.0\n",
      "8   101           1       0.0\n",
      "9   102           1       1.0\n",
      "10  103           1       1.0\n",
      "11  104           1       1.0\n"
     ]
    }
   ],
   "source": [
    "from hana_ml.dataframe import ConnectionContext\n",
    "from data_load_utils import DataSets, Settings\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\n",
    "connection_context = ConnectionContext(url, port, user, pwd)\n",
    "connection_context.get_current_schema()\n",
    "\n",
    "import unittest\n",
    "from hana_ml.algorithms.pal.unified_clustering import UnifiedClustering\n",
    "from hana_ml.model_storage import ModelStorage\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal, assert_series_equal\n",
    "import numpy as np\n",
    "data_gmm=connection_context.table('DATA_UNICU_GMM_TBL')\n",
    "data_gmm_predict=connection_context.table('DATA_UNICU_GMM_PREDICT_TBL')\n",
    "\n",
    "gmm_params = dict(init_param='farthest_first_traversal',\n",
    "                              n_components=2, covariance_type='full',\n",
    "                              shared_covariance=False, max_iter=500,\n",
    "                              error_tol=0.001, thread_ratio=0.5, random_seed=1)\n",
    "ugmm = UnifiedClustering(func = 'gaussianmixture', **gmm_params)\n",
    "ugmm.fit(data_gmm, key='ID')\n",
    "\n",
    "print(ugmm.model_.collect())\n",
    "expected_result = pd.DataFrame(data={\n",
    "    'ID':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    'CLUSTER_ID':[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "    'DISTANCE' : [None,None,None,None,None,None,None,None,None,None,None,None,None,None,None],\n",
    "    'SLIGHT_SILHOUETTE' : [None,None,None,None,None,None,None,None,None,None,None,None,None,None,None]})\n",
    "assert_series_equal(ugmm.labels_.head(15).collect()['CLUSTER_ID'],\n",
    "                    pd.Series(data=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], name = 'CLUSTER_ID'))\n",
    "               \n",
    "result = ugmm.predict(data_gmm_predict, key='ID' )\n",
    "print(result.collect())\n",
    "expected_result = pd.DataFrame(data={'ID':[99, 100, 101, 102, 103], \n",
    "                                     'CLUSTER_ID':[0, 0, 0, 0, 0], \n",
    "                                     'DISTANCE':[1.0, 1.0, 1.0, 0.0, 0.0]})\n",
    "assert_frame_equal(result.collect().head(5).set_index('ID'),\n",
    "                   expected_result.set_index('ID'), check_like=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
