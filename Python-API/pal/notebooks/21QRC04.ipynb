{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6d8aa2",
   "metadata": {},
   "source": [
    "What's New and Changed in version 2.11.211211\n",
    "---------------------------------------------\n",
    "New functions:\n",
    "\n",
    "    - Added FeatureSelection.\n",
    "    - Added BSTS.\n",
    "    - Added Word Cloud.\n",
    "    - Added hdbprocedure generation in pal_base and applied to all functions.\n",
    "    - Added GARCH.\n",
    "    - APL classification, regression, clustering: a new method, 'export_apply_code', generates code which can be used to apply a trained model outside APL.\n",
    "\n",
    "Enhancement:\n",
    "\n",
    "    - Enhanced Preprocessing with FeatureSelection.\n",
    "    - Enhanced the model storage with fit parameters in json format.\n",
    "    - Enhanced GARCH model with details.\n",
    "    - Enhanced PCA categorical support.\n",
    "    - Enhanced model storage with fit parameters info.\n",
    "    - Enhanced UnifiedExponentialSmoothing with massive mode.\n",
    "    - Enhanced AMDP generation as a function in unified_classification.\n",
    "    - Enhanced ARIMA with a explainer in the predict function.\n",
    "    - Enhanced additive_model_forecast with a explainer in the predict function.\n",
    "    - Enhanced HybridGradientBoostingClassifier with continue training of a trained HybridGradientBoostingClassifier model.\n",
    "    - Enhanced APL AutoTimeSeries with advanced predict outputs: the 'APL/ApplyExtraMode' parameter can be set in 'extra_applyout_settings'.\n",
    "    - Enhanced the stored procedure information retrieval.\n",
    "\n",
    "API change:\n",
    "\n",
    "    - Added 'background_size' in the init() and 'thread_ratio', 'top_k_attributions', 'trend_mod', 'trend_width', 'seasonal_width' in the predict() function of ARIMA() and AutoARIMA().\n",
    "    - Added 'show_explainer', 'decompose_seasonality', 'decompose_holiday' in the predict() function of additive_model_forecast().\n",
    "    - Added 'warm_start' in the fit() function of HybridGradientBoostingClassifier() and HybridGradientBoostingRegressor() for continuing training with exisiting model.\n",
    "\n",
    "Bug fixes:\n",
    "    - Fixed index creation bug in on-premise text_classification api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeba14c",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hana_ml import dataframe\n",
    "from hana_ml.algorithms.pal.utility import DataSets, Settings\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\n",
    "\n",
    "connection_context = dataframe.ConnectionContext(url, port, user, pwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.create_dataframe_from_pandas(connection_context,\n",
    "                                            pandas_df=pd.read_csv(\"https://raw.githubusercontent.com/SAP-samples/hana-ml-samples/main/Python-API/pal/datasets/21QRC04_feature_selection.csv\"),\n",
    "                                            table_name=\"#PAL_FS_TBL\",\n",
    "                                            force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903c6ac",
   "metadata": {},
   "source": [
    "- Statistical based FS methods:\n",
    "    - 'anova':Anova.\n",
    "    - 'chi-squared': Chi-squared.\n",
    "    - 'gini-index': Gini Index.\n",
    "    - 'fisher-score': Fisher Score.\n",
    "- Information theoretical based FS methods:\n",
    "    - 'information-gain': Information Gain.\n",
    "    - 'MRMR': Minimum Redundancy Maximum Relevance.\n",
    "    - 'JMI': Joint Mutual Infromation.\n",
    "    - 'IWFS': Interaction Weight Based Feature Selection.\n",
    "    - 'FCBF': Fast Correlation Based Filter.\n",
    "- Similarity based FS methods:\n",
    "    - 'laplacian-score': Laplacian Score.\n",
    "    - 'SPEC': Spectral Feature Selection.\n",
    "    - 'ReliefF': ReliefF.\n",
    "- Sparse Learning Based FS method:\n",
    "    - 'ADMM': ADMM.\n",
    "- Wrapper method:\n",
    "    - 'CSO': Competitive Swarm Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a451a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.preprocessing import FeatureSelection\n",
    "\n",
    "fs = FeatureSelection(fs_method='CSO', seed=1)\n",
    "fs_df = fs.fit_transform(df, label='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0d4ba",
   "metadata": {},
   "source": [
    "#### AMDP generator without sql_tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a67270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.unified_classification import UnifiedClassification\n",
    "\n",
    "full_set, diabetes_train, diabetes_test, _ = DataSets.load_diabetes_data(connection_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = dict(n_estimators=5, split_threshold=0, max_depth=10)\n",
    "rfc = UnifiedClassification(func=\"RandomDecisionTree\", **rfc_params)\n",
    "rfc.fit(diabetes_train, \n",
    "        key='ID', \n",
    "        label='CLASS', \n",
    "        categorical_variable=['CLASS'],\n",
    "        partition_method='stratified',\n",
    "        stratified_column='CLASS',)\n",
    "cm = rfc.confusion_matrix_.collect()\n",
    "rfc.predict(diabetes_test.drop(cols=['CLASS']), key=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb37763",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.create_amdp_class(amdp_name=\"DIABETES_AMDP\").build_amdp_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.write_amdp_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.model_storage import ModelStorage\n",
    "\n",
    "ms = ModelStorage(connection_context)\n",
    "ms.clean_up()\n",
    "rfc.name = \"RDT_AMDP\"\n",
    "ms.save_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77335f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd09117",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_load = ms.load_model(\"RDT_AMDP\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7693c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_load.create_amdp_class(amdp_name=\"DIABETES_AMDP\").build_amdp_class()\n",
    "print(rfc_load.amdp_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6af24",
   "metadata": {},
   "source": [
    "#### hdbprocedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfc.get_pal_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2580c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfc.get_fit_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfc.get_fit_output_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfc.fit_hdbprocedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883760c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfc.consume_fit_hdbprocedure(\"test1\", in_tables=[\"a1\"], out_tables=[\"b1\", \"b2\"])['base'], \"\\n\")\n",
    "print(rfc.consume_fit_hdbprocedure(\"test1\", in_tables=[\"a1\"], out_tables=[\"b1\", \"b2\"])['consume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e49565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfc.predict_hdbprocedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfc.consume_predict_hdbprocedure(\"test1\", in_tables=[\"a1\", \"a2\"], out_tables=[\"b1\", \"b2\"])['base'], \"\\n\")\n",
    "print(rfc.consume_predict_hdbprocedure(\"test1\", in_tables=[\"a1\", \"a2\"], out_tables=[\"b1\", \"b2\"])['consume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965817f",
   "metadata": {},
   "source": [
    "#### Time Series Explainer - ARIMA and Addtive Model Forecast\n",
    "\n",
    "Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77319afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import cholesky\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "\n",
    "num_samples = 600\n",
    "S1 = 12\n",
    "S2 = 100\n",
    "\n",
    "np.random.seed(seed=2334)\n",
    "\n",
    "x1 = norm.rvs(loc=0, scale=1, size=(1, num_samples))[0]\n",
    "x2 = norm.rvs(loc=0, scale=1, size=(1, num_samples))[0]\n",
    "x3 = norm.rvs(loc=0, scale=1, size=(1, num_samples))[0]\n",
    "x4 = norm.rvs(loc=0, scale=1, size=(1, num_samples))[0]\n",
    "\n",
    "std_m = np.array([\n",
    "    [6.8, 0, 0, 0],\n",
    "    [0, 1.4, 0, 0],\n",
    "    [0, 0, 1.4, 0],\n",
    "    [0, 0, 0, 2.9]\n",
    "])\n",
    "\n",
    "# specify desired correlation\n",
    "corr_m = np.array([\n",
    "    [1, .35, 0.33, 0.78],\n",
    "    [.35, 1, 0.90, 0.28],\n",
    "    [.33, 0.90, 1, 0.27],\n",
    "    [.78, 0.28, 0.27, 1]\n",
    "])\n",
    "\n",
    "# calc desired covariance (vc matrix)\n",
    "cov_m = np.dot(std_m, np.dot(corr_m, std_m))\n",
    "L = cholesky(cov_m, lower=True)\n",
    "corr_data = np.dot(L, [x1, x2, x3, x4]).T\n",
    "\n",
    "beta=np.array([-3.49, 13, 13, 0.0056])\n",
    "omega1 = 2*np.pi/S1\n",
    "omega2 = 2*np.pi/S2\n",
    "timestamp = np.array([i for i in range(num_samples)])\n",
    "y1 = np.multiply(50*rand(num_samples), 20*rand(1)*np.cos(omega1*timestamp)) \\\n",
    "+ np.multiply(32*rand(num_samples), 30*rand(1)*np.cos(3*omega1*timestamp)) \\\n",
    "+ np.multiply(rand(num_samples), rand(1)*np.sin(omega2*timestamp)) \n",
    "\n",
    "y2 = np.multiply(rand(num_samples), timestamp)\n",
    "y3 = corr_data.dot(beta.T)\n",
    "y = y1 + y2 + y3\n",
    "\n",
    "plt.plot(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9cd8d",
   "metadata": {},
   "source": [
    "#### ARIMA explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.tsa.auto_arima import AutoARIMA\n",
    "\n",
    "timestamp = [i for i in range(len(y))]\n",
    "raw = {'ID':timestamp, 'Y':y, 'X1':corr_data[:,0], 'X2':corr_data[:,1], 'X3':corr_data[:,2], 'X4':corr_data[:,3]}\n",
    "rdata = pd.DataFrame(raw)\n",
    "cutoff = (int)(rdata.shape[0]*0.9)\n",
    "\n",
    "df_fit = dataframe.create_dataframe_from_pandas(connection_context, rdata.iloc[:cutoff,:], table_name='PAL_ARIMA_FIT_TBL', force=True)\n",
    "df_predict = dataframe.create_dataframe_from_pandas(connection_context, rdata.iloc[cutoff:,:], table_name='PAL_ARIMA_PREDICT_TBL', force=True)\n",
    "\n",
    "arima= AutoARIMA(background_size=-1)\n",
    "arima.fit(df_fit, key='ID', endog='Y', exog=['X1', 'X2', 'X3', 'X4'])\n",
    "\n",
    "res = arima.predict(df_predict, top_k_attributions=30, seasonal_width=0.035, trend_width=0.035, show_explainer=True)\n",
    "\n",
    "print(res.head(5).collect())\n",
    "print(arima.explainer_.head(5).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc39dda",
   "metadata": {},
   "source": [
    "#### Additive Model Forecast explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.tsa import additive_model_forecast\n",
    "\n",
    "dates = pd.date_range('2018-01-01', '2019-08-23',freq='D')\n",
    "data_additive = {'ID':dates, 'Y':y, 'X1':corr_data[:,0], 'X2':corr_data[:,1], 'X3':corr_data[:,2], 'X4':corr_data[:,3]}\n",
    "data = pd.DataFrame(data_additive)\n",
    "cutoff = (int)(data.shape[0]*0.9)\n",
    "df_fit_additive = dataframe.create_dataframe_from_pandas(connection_context, data.iloc[:cutoff,:], table_name='PAL_ADDITIVE_FIT_TBL', force=True)\n",
    "df_predict_additive= dataframe.create_dataframe_from_pandas(connection_context, data.iloc[cutoff:,:], table_name='PAL_ADDITIVE_PREDICT_TBL', force=True)\n",
    "\n",
    "holiday_dic={\"Date\":['2018-01-01','2018-01-04','2018-01-05','2019-06-25','2019-06-29'],\n",
    "             \"Name\":['A', 'A', 'B', 'A', 'D']}\n",
    "df=pd.DataFrame(holiday_dic)\n",
    "df_holiday= dataframe.create_dataframe_from_pandas(connection_context, df, table_name='PAL_HOLIDAY_TBL', force=True)\n",
    "df_holiday=df_holiday.cast('Date', 'TIMESTAMP')\n",
    "\n",
    "amf = additive_model_forecast.AdditiveModelForecast(growth='linear',\n",
    "                                                    regressor = ['{\"NAME\": \"X1\", \"PRIOR_SCALE\":4, \"MODE\": \"additive\" }',\n",
    "                                                                 '{\"NAME\": \"X2\", \"PRIOR_SCALE\":4, \"MODE\": \"multiplicative\"}'],\n",
    "                                                    seasonality=['{ \"NAME\": \"yearly\", \"PERIOD\":365.25, \"FOURIER_ORDER\":10 }',\n",
    "                                                                 '{ \"NAME\": \"weekly\", \"PERIOD\":7, \"FOURIER_ORDER\":3 }',\n",
    "                                                                 '{ \"NAME\": \"daily\", \"PERIOD\":1, \"FOURIER_ORDER\":4 }'])\n",
    "\n",
    "amf.fit(df_fit_additive, key='ID', endog='Y', exog=['X1','X2','X3','X4'], holiday=df_holiday)\n",
    "model_content = amf.model_.collect()['MODEL_CONTENT']\n",
    "\n",
    "res = amf.predict(data=df_predict_additive, key= 'ID', show_explainer=True, decompose_seasonality=True, decompose_holiday=True)\n",
    "print(amf.explainer_.head(5).collect())\n",
    "print(amf.explainer_.head(15).collect()['SEASONAL'])\n",
    "print(amf.explainer_.head(15).collect()['HOLIDAY'])\n",
    "print(amf.explainer_.head(5).collect()['EXOGENOUS'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93f5c0",
   "metadata": {},
   "source": [
    "#### BSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ce5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.tsa.bsts import BSTS\n",
    "\n",
    "bt = BSTS(burn=0.6, expected_model_size=2,\n",
    "          seasonal_period=12, niter=2000,\n",
    "          seed=1)\n",
    "\n",
    "bt.fit(df_fit, key='ID', endog='Y', exog=['X1', 'X2', 'X3', 'X4'])\n",
    "\n",
    "fct_res = bt.predict(df_predict.deselect(\"Y\"), key='ID')[0]\n",
    "\n",
    "print(fct_res.head(3).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fit.head(10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf82076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fit.select([\"ID\", \"Y\"]).collect().to_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc54bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fit.save(\"GARCH_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a1957",
   "metadata": {},
   "source": [
    "#### GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b901bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.tsa.garch import GARCH\n",
    "gh = GARCH(p=1, q=1)\n",
    "gh.fit(data=df_fit.set_index('ID'), endog='Y')\n",
    "vari, stats = gh.predict(horizon=3)\n",
    "\n",
    "print(vari.head(3).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641fdcc",
   "metadata": {},
   "source": [
    "#### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"ID\" : ['doc1', 'doc2', 'doc3', 'doc4', 'doc5', 'doc6'],\n",
    "                     \"CONTENT\" : ['term1 term2 term2 term3 term3 term3',\n",
    "                                  'term2 term3 term3 term4 term4 term4',\n",
    "                                  'term3 term4 term4 term5 term5 term5',\n",
    "                                  'term3 term4 term4 term5 term5 term5 term5 term5 term5',\n",
    "                                  'term4 term6',\n",
    "                                  'term4 term6 term6 term6'],\n",
    "                     \"CATEGORY\" : ['CATEGORY_1', 'CATEGORY_1', 'CATEGORY_2', 'CATEGORY_2', 'CATEGORY_3', 'CATEGORY_3']})\n",
    "df_wc = dataframe.create_dataframe_from_pandas(connection_context=connection_context, pandas_df=data, table_name=\"#WC_DEMO\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.visualizers.word_cloud import WordCloud\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=2000,\n",
    "                      max_font_size=100, random_state=42, width=1000,\n",
    "                      height=860, margin=2).build(df_wc, content_column=\"CONTENT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68924fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9296b388",
   "metadata": {},
   "source": [
    "#### Parameterised view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57356c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view = connection_context.sql(\"\"\"\n",
    "SELECT *\n",
    "  FROM \"DBM2_RFULL_TBL\"\n",
    "  WHERE JOB=:job and AGE=:age;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view.save(\"TEST_VIEW2\", table_type=\"VIEW\",\n",
    "             view_structure={\"job\": \"VARCHAR(500)\", \"age\": \"INT\"}, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_view = connection_context.table(\"TEST_VIEW2\", view_params=('entrepreneur', 37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_view.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2bef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e8e26eb492012ce43ec3ea98c3fc2503d5495ecd40107dd94395e1e0d860e85"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
