{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Scenario: Analyze the Cash Flow of an Investment on a New Product\n",
    "\n",
    "Author: TI HDA DB HANA Core CN\n",
    "\n",
    "In this end-to-end scenario, we wish to do an analysis of the cash flow of an investment required to create a new product. Projected estimates are given for the product revenue, product costs, overheads, and capital investment for each year of the analysis, from which the cash flow can be calculated. For capital investment appraisal the cash flows are summed for each year and discounted for future values, in other words the net present value of the cash flow is derived as a single value measuring the benefit of the investment.\n",
    "\n",
    "The projected estimates are single point estimates of each data point and the analysis provides a single point value of project net present value (NPV). This is referred to as deterministic modeling, which is in contrast to probabilistic modeling whereby we examine the probability of outcomes, for example, what is the probability of a NPV greater than zero. Probabilistic modeling is also called Monte Carlo Simulation.\n",
    "\n",
    "Monte Carlo Simulation is used in our example to estimate the net present value (NPV) of the investment. The equations used in the simulation are:\n",
    "\n",
    "For each year i=0, 1, …, k\n",
    "\n",
    "Product margin(i) = product revenue(i) – product cost(i)\n",
    "\n",
    "Total profit(i) = product margin(i) – overhead(i)\n",
    "\n",
    "Cash flow(i) = total profit(i) – capital investment(i)\n",
    "\n",
    "Suppose the simulation covers k years’ time periods and the discount rate is r, the net present value of the investment is defined as:\n",
    "\n",
    "$ NPV \\ of \\ investment=\\sum_{i=0}^{k}{\\frac{Cash \\ flow_i}{(1+r)^i}}=\\sum_{i=0}^{k}{\\frac{product \\ revenue_i - product \\ cost_i-overhead_i-captical \\ flow_i}{(1+r)^i}}$\n",
    "\n",
    "\n",
    "## 1. Technology Background\n",
    "Monte Carlo Simulation is a computational algorithm that repeatedly generates random samples to compute numerical results based on a formula or model in order to obtain the unknown probability distribution of an event or outcome.\n",
    "\n",
    "In hana_ml, the Random Distribution Sampling, Distribution Fitting, and Cumulative Distribution algorithms may be used for Monte Carlo Simulation.\n",
    "\n",
    "## 2. Implementation Steps\n",
    "\n",
    "**Setup the Connection to SAP HANA**\n",
    "\n",
    "First, you need to create a connetion to a SAP HANA instance. In the following cell, we use a config file, config/e2edata.ini to control the connection parameters. \n",
    "\n",
    "In your case, please update the following url, port, user, pwd with your HANA instance information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.dataframe import ConnectionContext\n",
    "from hana_ml.algorithms.pal.utility import Settings\n",
    "\n",
    "# please update the following url, port, user, pwd with your HANA instance information\n",
    "connection_context = ConnectionContext(url, port, user, pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection functions samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(connection_context.connection.isconnected())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Dataset Generation\n",
    "\n",
    "Input the given estimates (single point deterministic values) for product revenue, product costs, overheads, and capital investment. In this example, the time periods are 5 (from year 1 to year 5).\n",
    "\n",
    "The probability distribution for each variable is assumed as follows and the unit is GBP:\n",
    "\n",
    "Product Revenue:\n",
    "Normal distribution and the mean and standard deviation are listed in the following table.\n",
    "\n",
    "Product Costs:\n",
    "Normal distribution and the mean and standard deviation are listed in the following table.\n",
    "\n",
    "Overheads:\n",
    "Uniform distribution and min and max values are listed in the following table.\n",
    "\n",
    "Capital Investment (for year 1 and year 2)\n",
    "Gamma distribution and shape and scale values are listed in the following table.\n",
    "\n",
    "|                        | Year 1 | Year 2 | Year 3 | Year 4 | Year 5 |\n",
    "|------------------------|--------|--------|--------|--------|--------|\n",
    "| **Product Revenue**    |        |        |        |        |        |\n",
    "| Mean                   | 0      | 3000   | 8000   | 18000  | 30000  |\n",
    "| Standard Deviation     | 0      | 300    | 800    | 1800   | 3000   |\n",
    "| **Product Costs**      |        |        |        |        |        |\n",
    "| Mean                   | 1000   | 1000   | 2500   | 7000   | 10000  |\n",
    "| Standard Deviation     | 75     | 75     | 187.5  | 525    | 750    |\n",
    "| **Overheads**          |        |        |        |        |        |\n",
    "| Mean                   | 1400   | 1800   | 2200   | 2600   | 3000   |\n",
    "| Standard Deviation     | 1500   | 2200   | 2800   | 3400   | 4000   |\n",
    "| **Capital Investment** |        |        |        |        |        |\n",
    "| Mean                   | 10000  | 2000   |        |        |        |\n",
    "| Standard Deviation     | 500    | 100    |        |        |        |\n",
    "\n",
    " \t \t \n",
    "Run the Random Distribution Sampling algorithm for each variable and generate 5,000 sample sets. The number of sample sets is a choice for the analysis. The larger the value then the more smooth the output distribution and the closer it will be to a normal distribution.\n",
    "\n",
    "**The first year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.random import normal, uniform\n",
    "\n",
    "number = 10\n",
    "\n",
    "def try_drop(conn_context, table_name):\n",
    "    try:\n",
    "        conn_context.drop_table(table=table_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Product Revenue:\n",
    "revenue_1 = normal(conn_context=connection_context, num_random=number, mean=0, sigma=0.01, seed=0)\n",
    "revenue_1 = revenue_1.rename_columns([\"ID\", \"RANDOM\"])\n",
    "\n",
    "try_drop(connection_context, \"REVENUE_1_TBL\")\n",
    "revenue_1.save(\"REVENUE_1_TBL\")\n",
    "\n",
    "# Product Costs:\n",
    "cost_1 = normal(conn_context=connection_context, num_random=number, mean=1000, sigma=75, seed=0)\n",
    "cost_1 = cost_1.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"COST_1_TBL\")  \n",
    "cost_1.save(\"COST_1_TBL\")\n",
    "\n",
    "# Overheads:\n",
    "overheads_1 = uniform(conn_context=connection_context, num_random=number, low=1400, high=1500, seed=0)\n",
    "overheads_1 = overheads_1.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"OVERHEADS_1_TBL\")\n",
    "overheads_1.save(\"OVERHEADS_1_TBL\")\n",
    "\n",
    "# Capital Investment (for year 1 and year 2)\n",
    "investment_1 = normal(conn_context=connection_context, num_random=number, mean=10000, sigma=500, seed=0)\n",
    "investment_1 = investment_1.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"INVESTMENT_1_TBL\")\n",
    "investment_1.save(\"INVESTMENT_1_TBL\")\n",
    "\n",
    "try_drop(connection_context, \"PAL_CASHFLOW_YEAR1\")\n",
    "connection_context.create_table(table=\"PAL_CASHFLOW_YEAR1\", \n",
    "                                table_structure={\"ID\":\"INTEGER\", \"CASH\":\"DOUBLE\"})\n",
    "\n",
    "cursor = connection_context.connection.cursor()\n",
    "sql = \"INSERT INTO PAL_CASHFLOW_YEAR1\" + \" SELECT REVENUE_1_TBL.ID, REVENUE_1_TBL.RANDOM - COST_1_TBL.RANDOM - OVERHEAD_1_TBL.RANDOM - INVESTMENT_1_TBL.RANDOM FROM REVENUE_1_TBL\" + \" LEFT JOIN COST_1_TBL ON REVENUE_1_TBL.ID = COST_1_TBL.ID\" +\" LEFT JOIN OVERHEAD_1_TBL ON REVENUE_1_TBL.ID = OVERHEAD_1_TBL.ID \" + \" LEFT JOIN INVESTMENT_1_TBL ON REVENUE_1_TBL.ID = INVESTMENT_1_TBL.ID;\"\n",
    "cursor.execute(sql) \n",
    "\n",
    "print(connection_context.table(\"REVENUE_1_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"COST_1_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"OVERHEAD_1_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"INVESTMENT_1_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"PAL_CASHFLOW_YEAR1\").head(3).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The second year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Revenue:\n",
    "revenue_2 = normal(connection_context, num_random=number, mean=3000, sigma=300, seed=0)\n",
    "revenue_2 = revenue_2.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"REVENUE_2_TBL\")  \n",
    "revenue_2.save(\"REVENUE_2_TBL\")\n",
    "\n",
    "# Product Costs:\n",
    "cost_2 = normal(connection_context, num_random=number, mean=1000, sigma=75, seed=0)\n",
    "cost_2 = cost_2.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"COST_2_TBL\")  \n",
    "cost_2.save(\"COST_2_TBL\")\n",
    "\n",
    "# Overheads:\n",
    "overheads_2 = uniform(connection_context, num_random=number, low=1800, high=2200, seed=0)\n",
    "overheads_2 = overheads_2.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"OVERHEADS_2_TBL\")  \n",
    "overheads_2.save(\"OVERHEADS_2_TBL\")\n",
    "\n",
    "# Capital Investment (for year 1 and year 2)\n",
    "investment_2 = normal(connection_context, num_random=number, mean=2000, sigma=100, seed=0)\n",
    "investment_2 = investment_2.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"INVESTMENT_2_TBL\")  \n",
    "investment_2.save(\"INVESTMENT_2_TBL\")\n",
    "\n",
    "try_drop(connection_context, \"PAL_CASHFLOW_YEAR2\")  \n",
    "connection_context.create_table(table=\"PAL_CASHFLOW_YEAR2\", \n",
    "                                table_structure={\"ID\":\"INTEGER\", \"CASH\":\"DOUBLE\"})\n",
    "sql = \"INSERT INTO PAL_CASHFLOW_YEAR2\" + \" SELECT REVENUE_2_TBL.ID, REVENUE_2_TBL.RANDOM - COST_2_TBL.RANDOM - OVERHEAD_2_TBL.RANDOM - INVESTMENT_2_TBL.RANDOM FROM REVENUE_2_TBL\" + \" LEFT JOIN COST_2_TBL ON REVENUE_2_TBL.ID = COST_2_TBL.ID\" +\" LEFT JOIN OVERHEAD_2_TBL ON REVENUE_2_TBL.ID = OVERHEAD_2_TBL.ID \" + \" LEFT JOIN INVESTMENT_2_TBL ON REVENUE_2_TBL.ID = INVESTMENT_2_TBL.ID;\"\n",
    "cursor.execute(sql) \n",
    "\n",
    "print(connection_context.table(\"REVENUE_2_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"COST_2_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"OVERHEAD_2_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"INVESTMENT_2_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"PAL_CASHFLOW_YEAR2\").head(3).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Revenue:\n",
    "revenue_3 = normal(connection_context, num_random=number, mean=8000, sigma=800, seed=0)\n",
    "revenue_3 = revenue_3.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"REVENUE_3_TBL\")  \n",
    "revenue_3.save(\"REVENUE_3_TBL\")\n",
    "\n",
    "# Product Costs:\n",
    "cost_3 = normal(connection_context, num_random=number, mean=2500, sigma=187.5, seed=0)\n",
    "cost_3 = cost_3.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"COST_3_TBL\")   \n",
    "cost_3.save(\"COST_3_TBL\")\n",
    "\n",
    "# Overheads:\n",
    "overheads_3 = uniform(connection_context, num_random=number, low=2200, high=2800, seed=0)\n",
    "overheads_3 = overheads_3.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"OVERHEADS_3_TBL\")  \n",
    "overheads_3.save(\"OVERHEADS_3_TBL\")\n",
    "\n",
    "try_drop(connection_context, \"PAL_CASHFLOW_YEAR3\")  \n",
    "connection_context.create_table(table=\"PAL_CASHFLOW_YEAR3\", \n",
    "                                table_structure={\"ID\":\"INTEGER\", \"CASH\":\"DOUBLE\"})\n",
    "sql = \"INSERT INTO PAL_CASHFLOW_YEAR3\" + \" SELECT REVENUE_3_TBL.ID, REVENUE_3_TBL.RANDOM - COST_3_TBL.RANDOM - OVERHEAD_3_TBL.RANDOM FROM REVENUE_3_TBL\" + \" LEFT JOIN COST_3_TBL ON REVENUE_3_TBL.ID = COST_3_TBL.ID\" + \" LEFT JOIN OVERHEAD_3_TBL ON REVENUE_3_TBL.ID = OVERHEAD_3_TBL.ID \"\n",
    "cursor.execute(sql) \n",
    "\n",
    "print(connection_context.table(\"REVENUE_3_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"COST_3_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"OVERHEAD_3_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"PAL_CASHFLOW_YEAR3\").head(3).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Revenue:\n",
    "revenue_4 = normal(connection_context, num_random=number, mean=18000, sigma=1800, seed=0)\n",
    "revenue_4 = revenue_4.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"REVENUE_4_TBL\")  \n",
    "revenue_4.save(\"REVENUE_4_TBL\")\n",
    "\n",
    "# Product Costs:\n",
    "cost_4 = normal(connection_context, num_random=number, mean=7000, sigma=525, seed=0)\n",
    "cost_4 = cost_4.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"COST_4_TBL\")     \n",
    "cost_4.save(\"COST_4_TBL\")\n",
    "\n",
    "# Overheads:\n",
    "overheads_4 = uniform(connection_context, num_random=number, low=2600, high=3400, seed=0)\n",
    "overheads_4 = overheads_4.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"OVERHEADS_4_TBL\")  \n",
    "overheads_4.save(\"OVERHEADS_4_TBL\")\n",
    "\n",
    "try_drop(connection_context, \"PAL_CASHFLOW_YEAR4\")  \n",
    "connection_context.create_table(table=\"PAL_CASHFLOW_YEAR4\", \n",
    "                                table_structure={\"ID\":\"INTEGER\", \"CASH\":\"DOUBLE\"})\n",
    "sql = \"INSERT INTO PAL_CASHFLOW_YEAR4\" + \" SELECT REVENUE_4_TBL.ID, REVENUE_4_TBL.RANDOM - COST_4_TBL.RANDOM - OVERHEAD_4_TBL.RANDOM FROM REVENUE_4_TBL\" + \" LEFT JOIN COST_4_TBL ON REVENUE_4_TBL.ID = COST_4_TBL.ID\" +\" LEFT JOIN OVERHEAD_4_TBL ON REVENUE_4_TBL.ID = OVERHEAD_4_TBL.ID \"\n",
    "cursor.execute(sql) \n",
    "\n",
    "print(connection_context.table(\"REVENUE_4_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"COST_4_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"OVERHEAD_4_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"PAL_CASHFLOW_YEAR4\").head(3).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Revenue:\n",
    "revenue_5 = normal(connection_context, num_random=number, mean=30000, sigma=3000, seed=0)\n",
    "revenue_5 = revenue_5.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"REVENUE_5_TBL\")  \n",
    "revenue_5.save(\"REVENUE_5_TBL\")\n",
    "\n",
    "# Product Costs:\n",
    "cost_5 = normal(connection_context, num_random=number, mean=5000, sigma=750, seed=0)\n",
    "cost_5 = cost_5.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"COST_5_TBL\")      \n",
    "cost_5.save(\"COST_5_TBL\")\n",
    "\n",
    "# Overheads:\n",
    "overheads_5 = uniform(connection_context, num_random=number, low=3000, high=4000, seed=0)\n",
    "overheads_5 = overheads_5.rename_columns([\"ID\", \"RANDOM\"])\n",
    "try_drop(connection_context, \"OVERHEADS_5_TBL\")  \n",
    "overheads_5.save(\"OVERHEADS_5_TBL\")\n",
    "\n",
    "try_drop(connection_context, \"PAL_CASHFLOW_YEAR5\")  \n",
    "connection_context.create_table(table=\"PAL_CASHFLOW_YEAR5\", \n",
    "                                table_structure={\"ID\":\"INTEGER\", \"CASH\":\"DOUBLE\"})\n",
    "sql = \"INSERT INTO PAL_CASHFLOW_YEAR5\" + \" SELECT REVENUE_5_TBL.ID, REVENUE_5_TBL.RANDOM - COST_5_TBL.RANDOM - OVERHEAD_5_TBL.RANDOM FROM REVENUE_5_TBL\" + \" LEFT JOIN COST_5_TBL ON REVENUE_5_TBL.ID = COST_5_TBL.ID\" +\" LEFT JOIN OVERHEAD_5_TBL ON REVENUE_5_TBL.ID = OVERHEAD_5_TBL.ID \"\n",
    "cursor.execute(sql) \n",
    "\n",
    "print(connection_context.table(\"REVENUE_5_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"COST_5_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"OVERHEAD_5_TBL\").head(3).collect())\n",
    "print(connection_context.table(\"PAL_CASHFLOW_YEAR5\").head(3).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Net Present Value Calculation\n",
    "\n",
    "Calculate the net present value of the investment by the following equation for each sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_drop(connection_context, \"NPV\")  \n",
    "connection_context.create_table(table=\"NPV\", \n",
    "                                table_structure={\"NPVALUE\":\"DOUBLE\"})\n",
    "cursor.execute(\"INSERT INTO NPV SELECT PAL_CASHFLOW_YEAR1.CASH + PAL_CASHFLOW_YEAR2.CASH/1.05 + PAL_CASHFLOW_YEAR3.CASH/POWER(1.05,2) +  PAL_CASHFLOW_YEAR4.CASH/POWER(1.05,3) + PAL_CASHFLOW_YEAR5.CASH/POWER(1.05,4) FROM PAL_CASHFLOW_YEAR1 LEFT JOIN PAL_CASHFLOW_YEAR2 ON PAL_CASHFLOW_YEAR1.ID = PAL_CASHFLOW_YEAR2.ID LEFT JOIN PAL_CASHFLOW_YEAR3 ON PAL_CASHFLOW_YEAR1.ID = PAL_CASHFLOW_YEAR3.ID LEFT JOIN PAL_CASHFLOW_YEAR4 ON PAL_CASHFLOW_YEAR1.ID = PAL_CASHFLOW_YEAR4.ID LEFT JOIN PAL_CASHFLOW_YEAR5 ON PAL_CASHFLOW_YEAR1.ID = PAL_CASHFLOW_YEAR5.ID;\")\n",
    "\n",
    "print(connection_context.table(\"NPV\").collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model Fitting\n",
    "\n",
    "Plot the distribution of the net present value of the investment and run Distribution Fitting to fit a normal distribution to the NPV of the investment as. (The Central Limit theorem states that the output distribution will be a normal distribution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.stats import distribution_fit\n",
    "\n",
    "npv = connection_context.table(\"NPV\")\n",
    "result_npv = distribution_fit(data=npv, \n",
    "                              distr_type=\"normal\",\n",
    "                              optimal_method=\"maximum_likelihood\", \n",
    "                              censored=False)\n",
    "print(result_npv[0].collect())\n",
    "print(result_npv[1].collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: CDF  \n",
    "\n",
    "According to the fitted model, run the Cumulative Distribution function to obtain the probability of having an NPV of investment smaller than or equal to a given NPV of the investment.\n",
    "\n",
    "Prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try_drop(connection_context, \"PAL_DISTRPROB_DATA_TBL\")  \n",
    "connection_context.create_table(table=\"PAL_DISTRPROB_DATA_TBL\", \n",
    "                                table_structure={\"DATACOL\":\"DOUBLE\"})\n",
    "\n",
    "cursor = connection_context.connection.cursor()\n",
    "values = [(7000,),(8000,),(9000,),(10000,),(11000,)]\n",
    "try:\n",
    "    cursor.executemany(\"INSERT INTO \" +\n",
    "                       \"{} VALUES ({})\".format(\"PAL_DISTRPROB_DATA_TBL\",\n",
    "                       \", \".join([\"?\"]*len(values[0]))), values)\n",
    "    connection_context.connection.commit()\n",
    "finally:\n",
    "    cursor.close()\n",
    "\n",
    "distri_prob_df = connection_context.table(\"PAL_DISTRPROB_DATA_TBL\")\n",
    "print(distri_prob_df.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke CDF and fetch the mean and variance from result.npv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.stats import cdf\n",
    "\n",
    "mean = float(result_npv[0].collect()[\"VALUE\"][1])\n",
    "sd = float(result_npv[0].collect()[\"VALUE\"][2])\n",
    "variance = sd*sd\n",
    "distr_info = {\"name\":\"normal\", \"mean\":mean, \"variance\":variance}\n",
    "\n",
    "result = cdf(distri_prob_df, distr_info, complementary=False)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Drop Tables and Close the HANA Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbls = (\"REVENUE_1_TBL\",\"REVENUE_2_TBL\", \"REVENUE_3_TBL\", \"REVENUE_4_TBL\", \"REVENUE_5_TBL\",\n",
    "        \"COST_1_TBL\",\"COST_2_TBL\", \"COST_3_TBL\",  \"COST_4_TBL\", \"COST_5_TBL\",\n",
    "        \"OVERHEADS_1_TBL\",\"OVERHEADS_2_TBL\", \"OVERHEADS_3_TBL\", \"OVERHEADS_4_TBL\", \"OVERHEADS_5_TBL\",\n",
    "        \"INVESTMENT_1_TBL\",\"INVESTMENT_2_TBL\",\n",
    "        \"PAL_CASHFLOW_YEAR1\",\"PAL_CASHFLOW_YEAR2\", \"PAL_CASHFLOW_YEAR3\", \"PAL_CASHFLOW_YEAR4\", \"PAL_CASHFLOW_YEAR5\",\n",
    "        \"NPV\", \"PAL_DISTRPROB_DATA_TBL\")\n",
    "\n",
    "for tab in tbls:\n",
    "    try:\n",
    "        connection_context.drop_table(table=tab)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "connection_context.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e8e26eb492012ce43ec3ea98c3fc2503d5495ecd40107dd94395e1e0d860e85"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
