{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## hana_ml Tutorial - COVID-19\n",
    "Author: SAP TI HA DB ML China\n",
    "\n",
    "Date: 2020/5/21\n",
    "\n",
    "In this tutorial, we will use SAP hana_ml to analyze the public dataset of COVID-19.\n",
    "\n",
    "## Dataset\n",
    "We use the public COVID-19 dataset from JHU, https://github.com/CSSEGISandData/COVID-19  (For tutorials only). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HANA Connection\n",
    "\n",
    "First, create a connetion to SAP HANA. To create a such connection, a config file, config/e2edata.ini is used to control the connection parameters.A sample section in the config file is shown below which includes HANA url, port, user and password information.<br>\n",
    "\n",
    "###################<br>\n",
    "[hana]<br>\n",
    "url=host-url<br>\n",
    "user=username<br>\n",
    "passwd=userpassword<br>\n",
    "port=3xx15<br>\n",
    "###################<br>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.dataframe import ConnectionContext\r\n",
    "from hana_ml.algorithms.pal.utility import DataSets, Settings\r\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\r\n",
    "connection_context = ConnectionContext(url, port, user, pwd)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Connection functions samples:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(connection_context.connection.isconnected())\r\n",
    "print(connection_context.has_table(table='T1'))\r\n",
    "print(connection_context.get_current_schema())\r\n",
    "print(connection_context.hana_version())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## hana_ml DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. worldwide-aggregated dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\r\n",
    "\r\n",
    "worldwide_df = DataSets.load_covid_data(connection_context)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Coverts to Pandas dataframe with collect():"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "worldwide_df.head(3).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "worldwide_df.dtypes()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "worldwide_df.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "worldwide = worldwide_df.collect()\r\n",
    "fig, ax = plt.subplots()\r\n",
    "fig.set_size_inches(10, 7)\r\n",
    "ax.set_ylabel('Number', fontsize='x-large')\r\n",
    "ax.set_xlabel('Date', fontsize='x-large')\r\n",
    "ax.set_title('Global Confirmed COVID-19 Cases', fontsize='xx-large')\r\n",
    "ax.plot(worldwide['Date'], worldwide['Confirmed'], 'k--', label='Confirmed')\r\n",
    "ax.plot(worldwide['Date'], worldwide['Deaths'], 'b--', label='Deaths')\r\n",
    "ax.plot(worldwide['Date'], worldwide['Recovered'], 'g--', label='Recovered')\r\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='x-large')\r\n",
    "Date = worldwide['Date']\r\n",
    "xticks=list(range(0,len(Date),14)) \r\n",
    "xlabels=[Date[x] for x in xticks] \r\n",
    "ax.set_xticks(xticks)\r\n",
    "ax.set_xticklabels(xlabels, rotation=40)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. time_series_covid19_confirmed_US dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "# Load data, drop unneeded lat/long columns and group by country/region\r\n",
    "def loadAndGroup(fileName, groupBy=\"Province_State\", dropColumns=[\"UID\",\"iso2\",\"iso3\",\"code3\",\"FIPS\",\"Admin2\",\"Country_Region\",\"Lat\",\"Long_\",\"Combined_Key\"], extraDrop=[]):   #,\"Population\"\r\n",
    "    df=pd.read_csv(fileName)\r\n",
    "    for dc in dropColumns+extraDrop:\r\n",
    "        df.drop(dc, axis=1, inplace=True)\r\n",
    "    df=df.groupby(groupBy).sum()\r\n",
    "    for dc in range(30):\r\n",
    "        df.drop(df.columns[0], axis=1, inplace=True)\r\n",
    "    return df\r\n",
    "\r\n",
    "def diff(ys):\r\n",
    "    res=[0]\r\n",
    "    cur=ys[0]\r\n",
    "    for y in ys[1:]:\r\n",
    "        res.append(y-cur)\r\n",
    "        cur=y\r\n",
    "    return res\r\n",
    "\r\n",
    "confd         =loadAndGroup('../datasets/time_series_covid19_confirmed_US.csv')\r\n",
    "confd         =confd.append(confd.sum(axis=0).rename('US'))\r\n",
    "confdDelta    =confd.diff(axis=1).replace(np.nan, 0)\r\n",
    "\r\n",
    "# Preprocess the Data to transpose and add a 'timestamp' column as the first column.\r\n",
    "def preprocessData(df):\r\n",
    "    df_new = pd.DataFrame(df).T\r\n",
    "    id= df_new.index\r\n",
    "    col_name=df_new.columns.tolist()\r\n",
    "    col_name.insert(0, 'Timestamp')  \r\n",
    "    df_new=df_new.reindex(columns=col_name)\r\n",
    "    df_new['Timestamp']=id\r\n",
    "    return(df_new)\r\n",
    "\r\n",
    "confd_df=preprocessData(confd)\r\n",
    "confdDelta_df=preprocessData(confdDelta)\r\n",
    "\r\n",
    "confd_df_hana = create_dataframe_from_pandas(connection_context=connection_context, pandas_df=confd_df, table_name='US_CONFIRMED', force=True, replace=True)\r\n",
    "confdDelta_df_hana = create_dataframe_from_pandas(connection_context=connection_context, pandas_df=confdDelta_df, table_name='US_CONFIRMED_DELTA', force=True, replace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confd_us = connection_context.table('US_CONFIRMED')\r\n",
    "confd_us_delta = connection_context.table('US_CONFIRMED_DELTA')\r\n",
    "print(confd_us)\r\n",
    "print(confd_us_delta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confd_us.head(3).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confd_us_delta.collect().head(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(confd_us.count())\r\n",
    "print(confd_us_delta.count())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ny_confirmed = confd_us.select('New York').collect()\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "fig, ax = plt.subplots()\r\n",
    "fig.set_size_inches(10, 7)\r\n",
    "ax.set_ylabel('Number', fontsize='x-large')\r\n",
    "ax.set_xlabel('Date', fontsize='x-large')\r\n",
    "ax.set_title('Cumulative COVID-19 Cases in New York', fontsize='xx-large')\r\n",
    "ax.plot(confd_us.collect()['Timestamp'], ny_confirmed, 'b-o', label=\"Confirmed\")\r\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='x-large')\r\n",
    "Date = confd_us.collect()['Timestamp']\r\n",
    "xticks=list(range(0,len(Date),7)) \r\n",
    "xlabels=[Date[x] for x in xticks] \r\n",
    "ax.set_xticks(xticks)\r\n",
    "ax.set_xticklabels(xlabels, rotation=40)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ny_confirmed_delta = confd_us_delta.select('New York').collect()\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "fig, ax = plt.subplots()\r\n",
    "fig.set_size_inches(10,7)\r\n",
    "ax.set_ylabel('Number', fontsize='x-large')\r\n",
    "ax.set_xlabel('Date', fontsize='x-large')\r\n",
    "ax.set_title('Daily New Cases of Covid-19 in New York', fontsize='xx-large')\r\n",
    "ax.plot(confd_us_delta.collect()['Timestamp'], ny_confirmed_delta, 'b-o', label=\"Daily New York Confirmed\")\r\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='large')\r\n",
    "Date = confd_us_delta.collect()['Timestamp']\r\n",
    "xticks=list(range(0,len(Date),7)) \r\n",
    "xlabels=[Date[x] for x in xticks] \r\n",
    "ax.set_xticks(xticks)\r\n",
    "ax.set_xticklabels(xlabels, rotation=40)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forecast "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Time Series Forecast Algorithms - Auto ARIMA, Additive Model Forecast"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Auto ARIMA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ny_confd_delta = confd_us_delta.select('New York').add_id('ID').cast('New York', 'INT')\r\n",
    "print(ny_confd_delta.head(5).collect())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.tsa.auto_arima import AutoARIMA\r\n",
    "\r\n",
    "autoarima = AutoARIMA()\r\n",
    "autoarima.fit(ny_confd_delta, key=\"ID\")\r\n",
    "\r\n",
    "print(autoarima.model_.collect().head(5))\r\n",
    "print(autoarima.fitted_.collect().head(10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "fig, ax = plt.subplots()\r\n",
    "fig.set_size_inches(13, 8)\r\n",
    "ax.set_ylabel('Number', fontsize='x-large')\r\n",
    "ax.set_xlabel('Date', fontsize='x-large')\r\n",
    "ax.set_title('New Cases of COVID-19 in New York Fitted with Auto ARIMA Model', fontsize='xx-large')\r\n",
    "ax.plot(ny_confd_delta.collect()['ID'], ny_confd_delta.collect()['New York'], 'b--', label = 'Daily New Cases')\r\n",
    "ax.plot(autoarima.fitted_.collect()['ID'], autoarima.fitted_.collect()['FITTED'],'r--', label='AutoARIMA fitted')\r\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='x-large')\r\n",
    "Date = confd_us_delta.collect()['Timestamp']\r\n",
    "xticks=list(range(0,len(Date),7)) \r\n",
    "xlabels=[Date[x] for x in xticks] \r\n",
    "ax.set_xticks(xticks)\r\n",
    "ax.set_xticklabels(xlabels, rotation=40)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Storage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.model_storage import ModelStorage\r\n",
    "# model storage must use the same connection as the model\r\n",
    "model_storage = ModelStorage(connection_context=connection_context)\r\n",
    "\r\n",
    "# Saves the model\r\n",
    "autoarima.name = 'ARIMA model' \r\n",
    "autoarima.version = 1\r\n",
    "model_storage.save_model(model=autoarima, if_exists='replace')\r\n",
    "\r\n",
    "autoarima.name = 'ARIMA model' \r\n",
    "autoarima.version = 2\r\n",
    "model_storage.save_model(model=autoarima, if_exists='replace')\r\n",
    "\r\n",
    "# Lists models\r\n",
    "model_storage.list_models()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_storage.delete_model('ARIMA model', 2)\r\n",
    "model_storage.list_models()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_storage.list_models()['JSON'].iloc[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = model_storage.load_model(name='ARIMA model', version=1)\r\n",
    "print(model.model_.collect().head(5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict with ARIMA Model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.set_conn(connection_context)\r\n",
    "result = model.predict(forecast_length=5)\r\n",
    "print(result.collect())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "id_predict = list(range(90,95))\r\n",
    "id_all = list(range(1,94))\r\n",
    "\r\n",
    "data_fitted_predict = autoarima.fitted_.collect()['FITTED'].append(result.collect()['FORECAST'])\r\n",
    "data_fitted = ny_confd_delta.collect()['New York']\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "fig.set_size_inches(13, 8)\r\n",
    "ax.set_ylabel('Number', fontsize='x-large')\r\n",
    "ax.set_xlabel('Date', fontsize='x-large')\r\n",
    "ax.set_title('New Cases of COVID-19 in New York Forecast', fontsize='xx-large')\r\n",
    "ax.plot(ny_confd_delta.collect()['ID'], data_fitted, 'k--', label='Daily confirmed')\r\n",
    "ax.plot(id_all, data_fitted_predict[1:94], 'r--', label='ARIMA fitted and forecast')\r\n",
    "ax.plot(id_predict,  result.collect()['HI80'], 'b--', label='High 80% value')\r\n",
    "ax.plot(id_predict,  result.collect()['HI95'], 'g--', label='High 95% value')\r\n",
    "ax.plot(id_predict,  result.collect()['LO80'], 'y--', label='Low 80% value')\r\n",
    "ax.plot(id_predict,  result.collect()['LO95'], 'c--', label='Low 95% value')\r\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='x-large')\r\n",
    "Date = confd_us_delta.collect()['Timestamp']\r\n",
    "#Date.append(pd.DataFrame(['5/20/20', '5/21/20', '5/22/20', '5/23/20', '5/24/20']))\r\n",
    "xticks=list(range(0,len(Date),7)) \r\n",
    "xlabels=[Date[x] for x in xticks] \r\n",
    "ax.set_xticks(xticks)\r\n",
    "ax.set_xticklabels(xlabels, rotation=40)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Additive Model Forecast"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ny_confd_delta = confd_us_delta.select('Timestamp','New York').cast('New York', 'INT')\r\n",
    "ny_confd_delta = ny_confd_delta.cast('Timestamp', 'DATE')\r\n",
    "print(ny_confd_delta.head(3).collect())\r\n",
    "print(ny_confd_delta.dtypes())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predicted data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.dataframe import create_dataframe_from_pandas\r\n",
    "data = {\r\n",
    "    'Timestamp':['2020-5-20', '2020-5-21', '2020-5-22', '2020-5-23', '2020-5-24'],\r\n",
    "    'New York':[0, 0, 0, 0, 0]\r\n",
    "}\r\n",
    "predict = pd.DataFrame(data)\r\n",
    "predict_df = create_dataframe_from_pandas(connection_context=connection_context, pandas_df= predict, table_name='ADDITIVE_PREDICT_TBL', force=True, replace=True)\r\n",
    "predict_df = predict_df.cast('New York', 'DOUBLE')\r\n",
    "predict_df = predict_df.cast('Timestamp', 'DATE')\r\n",
    "print(predict_df.collect())\r\n",
    "print(predict_df.dtypes())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.tsa import additive_model_forecast\r\n",
    "\r\n",
    "amf = additive_model_forecast.AdditiveModelForecast()\r\n",
    "amf.fit(ny_confd_delta)\r\n",
    "\r\n",
    "print(amf.model_.collect())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = amf.predict(predict_df)\r\n",
    "print(result.collect())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "id_predict = list(range(90,95))\r\n",
    "id_all = list(range(1,95))\r\n",
    "\r\n",
    "data_all = ny_confd_delta.collect()['New York'].append(result.collect()['YHAT']) \r\n",
    "upper = result.collect()['YHAT_UPPER']\r\n",
    "lower = result.collect()['YHAT_LOWER']\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "fig.set_size_inches(13, 8)\r\n",
    "ax.set_ylabel('Number', fontsize='x-large')\r\n",
    "ax.set_xlabel('Date', fontsize='x-large')\r\n",
    "ax.set_title('New Cases of COVID-19 in New York Forecast - Addictive Model Forecast', fontsize='xx-large')\r\n",
    "ax.plot(id_all[1:89], data_all[1:89], 'k--', label='confirmed')\r\n",
    "ax.plot(id_all[89:94], data_all[89:94], 'r--', label='predict data')\r\n",
    "ax.plot(id_predict,  upper, 'b--', label='upper bound')\r\n",
    "ax.plot(id_predict,  lower, 'c--', label='lower bound')\r\n",
    "Date = confd_us_delta.collect()['Timestamp']\r\n",
    "#Date.append(pd.DataFrame(['5/20/20', '5/21/20', '5/22/20', '5/23/20', '5/24/20']))\r\n",
    "xticks=list(range(0,len(Date),7)) \r\n",
    "xlabels=[Date[x] for x in xticks] \r\n",
    "ax.set_xticks(xticks)\r\n",
    "ax.set_xticklabels(xlabels, rotation=40)\r\n",
    "plt.show()\r\n",
    "legend = ax.legend(loc='upper left', shadow=True, fontsize='x-large')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression - SVR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ny_confd_delta = confd_us_delta.select('New York').cast('New York', 'INT')\n",
    "print(ny_confd_delta.head(3).collect())\n",
    "print(ny_confd_delta.dtypes())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    " \n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):    \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    " \n",
    "values = pd.DataFrame(ny_confd_delta.collect()['New York'])\n",
    "regression_data = series_to_supervised(values, 5)\n",
    "print(regression_data.head(5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svr_df = create_dataframe_from_pandas(connection_context=connection_context, pandas_df=regression_data, table_name='NY_SVR_DATA_TBL', force=True, replace=True)\n",
    "svr_df =svr_df.add_id('ID')\n",
    "print(svr_df.head(3).collect())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training\n",
    "Split the dataset into train_data and test_data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.partition import train_test_val_split\n",
    "train_data, test_data, validate_data = train_test_val_split(svr_df, training_percentage=0.8, testing_percentage=0.2, validation_percentage=0)\n",
    "print(train_data.count())\n",
    "print(train_data.collect().head(3))\n",
    "print(test_data.count())\n",
    "print(test_data.collect().head(3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.svm import SVR\n",
    "featurs_svr = ['var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)']\n",
    "svr = SVR(kernel = 'rbf',\n",
    "          scale_info='standardization', \n",
    "          gamma = 0.3,\n",
    "          random_state=10,\n",
    "          scale_label=True)\n",
    "svr.fit(train_data, key='ID', features = featurs_svr, label = 'var1(t)')\n",
    "\n",
    "print(svr.model_.collect())\n",
    "print(svr.stat_.collect())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Score\n",
    "Calculate the r2_score:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(svr.score(test_data, key='ID', features = featurs_svr, label = 'var1(t)'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svr_cv = SVR(kernel='rbf', \n",
    "             scale_info='standardization', \n",
    "             scale_label=True, \n",
    "             resampling_method='cv',\n",
    "             fold_num=10, \n",
    "             repeat_times=5,\n",
    "             random_state=11,\n",
    "             search_strategy='grid',\n",
    "             param_range = [('gamma', [0.1, 0.1, 1.0])])\n",
    "svr_cv.fit(train_data, key='ID', label = 'var1(t)')\n",
    "\n",
    "print(svr_cv.model_.collect())\n",
    "print(svr_cv.stat_.collect())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(svr_cv.score(test_data, key='ID', features = featurs_svr, label = 'var1(t)'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Close HANA Connection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "connection_context.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "9e8e26eb492012ce43ec3ea98c3fc2503d5495ecd40107dd94395e1e0d860e85"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}