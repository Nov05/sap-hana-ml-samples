{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "What's New and Changed in version 2.8.210321\n",
    "--------------------------------------------\n",
    "\n",
    "Version 2.8.210321 supports **SAP HANA SPS05** and **SAP HANA Cloud**\n",
    "\n",
    "Enhancement:\n",
    "\n",
    "    - Enhanced sql() to enable multiline execution.\n",
    "    - Enhanced save() to add append option.\n",
    "    - Enhanced diff() to enable negative input.\n",
    "    - Enhanced model report functionality of UnifiedClassification with added model and data visualization.\n",
    "    - Enhanced dataset_report module with a optimized process of report generation and better user experience.\n",
    "    - Enhanced UnifiedClustering to support 'distance_level' in AgglomerateHierarchicalClustering and DBSCAN functions. Please refer to documentation for details.\n",
    "    - Enahnced model storage to support unified report.\n",
    "\n",
    "New functions:\n",
    "\n",
    "    - Added generate_html_report() and generate_notebook_iframe_report() functions for UnifiedRegression which could display the output, e.g. statistic and model.\n",
    "    - APL Gradient Boosting: the **other_params** parameter is now supported.\n",
    "    - APL all models: a new method, **get_model_info**, is created, allowing users to retrieve the summary and the performance metrics of a saved model.\n",
    "    - APL all models: users can now specify the weight of explanatory variables via the **weight** parameter.\n",
    "    - Added LSTM.\n",
    "    - Added Text Mining functions support for both SAP HANA on-premise and cloud version.\n",
    "        - tf_analysis\n",
    "        - text_classification\n",
    "        - get_related_doc\n",
    "        - get_related_term\n",
    "        - get_relevant_doc\n",
    "        - get_relevant_term\n",
    "        - get_suggested_term\n",
    "    - Added unified report.\n",
    "\n",
    "New dependency:\n",
    "\n",
    "    - Added new dependency 'htmlmin' for generating dataset and model report.\n",
    "\n",
    "API change:\n",
    "\n",
    "    - KMeans with two added parameters 'use_fast_library' and 'use_float'.\n",
    "    - UnifiedRegression with one added parameter 'build_report'.\n",
    "    - Added a parameter 'distance_level' in UnifiedClustering when 'func' is AgglomerateHierarchicalClustering and DBSCAN. Please refer to documentation for details.\n",
    "    - Renamed 'batch_size' with 'chunk_size' in create_dataframe_from_pandas.\n",
    "    - OnlineARIMA has two added parameters 'random_state', 'random_initialization' and its partial_fit() function supports two parameters 'learning_rate' and 'epsilon' for updating the values in the input model.\n",
    "\n",
    "Bug fixes:\n",
    "\n",
    "    - Fixed onlineARIMA model storage support.\n",
    "    - Fixed inflexible default locations of selected columns of input data, e.g. key, features and endog.\n",
    "    - Fixed accuracy_measure issue in AutoExponentialSmoothing.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiline SQL execution\n",
    "\n",
    "We've enhanced connection context's sql function to support multiline sql execution and return the last query statement."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.dataframe import ConnectionContext\r\n",
    "from hana_ml.algorithms.pal.utility import Settings, DataSets\r\n",
    "url, port, user, pwd = Settings.load_config(\"../../config/e2edata.ini\")\r\n",
    "# the connection\r\n",
    "connection_context = ConnectionContext(url, port, user, pwd)\r\n",
    "df = connection_context.sql(\r\n",
    "\"\"\"\r\n",
    "DO\r\n",
    "BEGIN\r\n",
    "outtab = SELECT 1 KEY, 2.2 ENDOG FROM DUMMY;\r\n",
    "CREATE LOCAL TEMPORARY TABLE #AABB AS (SELECT * FROM :outtab);\r\n",
    "END;\r\n",
    "\r\n",
    "SELECT * FROM #AABB\r\n",
    "\"\"\"\r\n",
    ")\r\n",
    "df.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM\n",
    "Data from PAL example."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "datalist = [\r\n",
    "                (0 ,20.7),\r\n",
    "                (1 ,17.9),\r\n",
    "                (2 ,18.8),\r\n",
    "                (3 ,14.6),\r\n",
    "                (4 ,15.8),\r\n",
    "                (5 ,15.8),\r\n",
    "                (6 ,15.8),\r\n",
    "                (7 ,17.4),\r\n",
    "                (8 ,21.8),\r\n",
    "                (9 ,20),\r\n",
    "                (10,16.2),\r\n",
    "                (11,13.3),\r\n",
    "                (12,16.7),\r\n",
    "                (13,21.5),\r\n",
    "                (14,25),\r\n",
    "                (15,20.7),\r\n",
    "                (16,20.6),\r\n",
    "                (17,24.8),\r\n",
    "                (18,17.7),\r\n",
    "                (19,15.5),\r\n",
    "                (20,18.2),\r\n",
    "                (21,12.1),\r\n",
    "                (22,14.4),\r\n",
    "                (23,16),\r\n",
    "                (24,16.5),\r\n",
    "                (25,18.7),\r\n",
    "                (26,19.4),\r\n",
    "                (27,17.2),\r\n",
    "                (28,15.5),\r\n",
    "                (29,15.1),\r\n",
    "                (30,15.4),\r\n",
    "                (31,15.3),\r\n",
    "                (32,18.8),\r\n",
    "                (33,21.9),\r\n",
    "                (34,19.9),\r\n",
    "                (35,16.6),\r\n",
    "                (36,16.8),\r\n",
    "                (37,14.6),\r\n",
    "                (38,17.1),\r\n",
    "                (39,25),\r\n",
    "                (40,15),\r\n",
    "                (41,13.7),\r\n",
    "                (42,13.9),\r\n",
    "                (43,18.3),\r\n",
    "                (44,22),\r\n",
    "                (45,22.1),\r\n",
    "                (46,21.2),\r\n",
    "                (47,18.4),\r\n",
    "                (48,16.6),\r\n",
    "                (49,16.1),\r\n",
    "                (50,15.7),\r\n",
    "                (51,16.6),\r\n",
    "                (52,16.5),\r\n",
    "                (53,14.4),\r\n",
    "                (54,14.4),\r\n",
    "                (55,18.5),\r\n",
    "                (56,16.9),\r\n",
    "                (57,17.5),\r\n",
    "                (58,21.2),\r\n",
    "                (59,17.8),\r\n",
    "                (60,18.6),\r\n",
    "                (61,17),\r\n",
    "                (62,16),\r\n",
    "                (63,13.3),\r\n",
    "                (64,14.3),\r\n",
    "                (65,11.4),\r\n",
    "                (66,16.3),\r\n",
    "                (67,16.1),\r\n",
    "                (68,11.8),\r\n",
    "                (69,12.2),\r\n",
    "                (70,14.7),\r\n",
    "                (71,11.8),\r\n",
    "                (72,11.3),\r\n",
    "                (73,10.6),\r\n",
    "                (74,11.7),\r\n",
    "                (75,14.2),\r\n",
    "                (76,11.2),\r\n",
    "                (77,16.9),\r\n",
    "                (78,16.7),\r\n",
    "                (79,8.1),\r\n",
    "                (80,8),\r\n",
    "                (81,8.8),\r\n",
    "                (82,13.4),\r\n",
    "                (83,10.9),\r\n",
    "                (84,13.4),\r\n",
    "                (85,11),\r\n",
    "                (86,15),\r\n",
    "                (87,15.7),\r\n",
    "                (88,14.5),\r\n",
    "                (89,15.8),\r\n",
    "                (90,16.7),\r\n",
    "                (91,16.8),\r\n",
    "                (92,17.5),\r\n",
    "                (93,17.1),\r\n",
    "                (94,18.1),\r\n",
    "                (95,16.6),\r\n",
    "                (96,10),\r\n",
    "                (97,14.9),\r\n",
    "                (98,15.9),\r\n",
    "                (99,13)]\r\n",
    "datalist_predict = [\r\n",
    "        (0,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9,15.5,16.4,14.5,12.6,13.6,11.2,11,12),\r\n",
    "        (1,11.9,14.7,9.4,6.6,7.9,11,15.7,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1),\r\n",
    "        (2,14.7,9.4,6.6,7.9,11,15.7,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13),\r\n",
    "        (3,9.4,6.6,7.9,11,15.7,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4),\r\n",
    "        (4,6.6,7.9,11,15.7,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3),\r\n",
    "        (5,7.9,11,15.7,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9),\r\n",
    "        (6,11,15.7,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12),\r\n",
    "        (7,15.7,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7),\r\n",
    "        (8,15.2,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6),\r\n",
    "        (9,15.9,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3),\r\n",
    "        (10,10.6,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7),\r\n",
    "        (11,8.3,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2),\r\n",
    "        (12,8.6,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5),\r\n",
    "        (13,12.7,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9),\r\n",
    "        (14,10.5,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9,15.5),\r\n",
    "        (15,12,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9,15.5,16.4),\r\n",
    "        (16,11.1,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9,15.5,16.4,14.5),\r\n",
    "        (17,13,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9,15.5,16.4,14.5,12.6),\r\n",
    "        (18,12.4,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9,15.5,16.4,14.5,12.6,13.6),\r\n",
    "        (19,13.3,15.9,12,13.7,17.6,14.3,13.7,15.2,14.5,14.9,15.5,16.4,14.5,12.6,13.6,11.2)\r\n",
    "        ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\r\n",
    "lstm_data = create_dataframe_from_pandas(connection_context=connection_context,\r\n",
    "                                         pandas_df=pd.DataFrame(datalist, columns=[\"KEY\", \"VALUE\"]),\r\n",
    "                                         table_name=\"#LSTM_TRAIN\",\r\n",
    "                                         force=True)\r\n",
    "lstm_predict = create_dataframe_from_pandas(connection_context=connection_context,\r\n",
    "                                            pandas_df=pd.DataFrame(datalist_predict, columns=[\"ID\",\r\n",
    "                                                                                              \"VAL1\",\r\n",
    "                                                                                              \"VAL2\",\r\n",
    "                                                                                              \"VAL3\",\r\n",
    "                                                                                              \"VAL4\",\r\n",
    "                                                                                              \"VAL5\",\r\n",
    "                                                                                              \"VAL6\",\r\n",
    "                                                                                              \"VAL7\",\r\n",
    "                                                                                              \"VAL8\",\r\n",
    "                                                                                              \"VAL9\",\r\n",
    "                                                                                              \"VAL10\",\r\n",
    "                                                                                              \"VAL11\",\r\n",
    "                                                                                              \"VAL12\",\r\n",
    "                                                                                              \"VAL13\",\r\n",
    "                                                                                              \"VAL14\",\r\n",
    "                                                                                              \"VAL15\",\r\n",
    "                                                                                              \"VAL16\" ]),\r\n",
    "                                         table_name=\"#LSTM_PREIDCT\",\r\n",
    "                                         force=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.tsa import lstm\r\n",
    "lstm = lstm.LSTM(gru='lstm',\r\n",
    "                 bidirectional=False,\r\n",
    "                 time_dim=16,\r\n",
    "                 max_iter=1000,\r\n",
    "                 learning_rate=0.01,\r\n",
    "                 batch_size=32,\r\n",
    "                 hidden_dim=128,\r\n",
    "                 num_layers=1,\r\n",
    "                 interval=1,\r\n",
    "                 stateful=False,\r\n",
    "                 optimizer_type='Adam')\r\n",
    "lstm.fit(lstm_data)\r\n",
    "res = lstm.predict(lstm_predict)\r\n",
    "res.head(2).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SHAPLEY Explainer in Unified Classification\n",
    "Diabetes data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.algorithms.pal.model_selection import GridSearchCV\r\n",
    "from hana_ml.algorithms.pal.unified_classification import UnifiedClassification\r\n",
    "\r\n",
    "full_set, diabetes_train, diabetes_test, _ = DataSets.load_diabetes_data(connection_context)\r\n",
    "\r\n",
    "uc_hgbdt = UnifiedClassification('HybridGradientBoostingTree')\r\n",
    "\r\n",
    "gscv = GridSearchCV(estimator=uc_hgbdt, \r\n",
    "                    param_grid={'learning_rate': [0.1, 0.4, 0.7, 1],\r\n",
    "                                'n_estimators': [4, 6, 8, 10],\r\n",
    "                                'split_threshold': [0.1, 0.4, 0.7, 1]},\r\n",
    "                    train_control=dict(fold_num=5,\r\n",
    "                                       resampling_method='cv',\r\n",
    "                                       random_state=1,\r\n",
    "                                       ref_metric=['auc']),\r\n",
    "                    scoring='error_rate')\r\n",
    "gscv.fit(data=diabetes_train, key= 'ID',\r\n",
    "         label='CLASS',\r\n",
    "         partition_method='stratified',\r\n",
    "         partition_random_state=1,\r\n",
    "         stratified_column='CLASS',\r\n",
    "         build_report=True)\r\n",
    "features = diabetes_train.columns\r\n",
    "features.remove('CLASS')\r\n",
    "features.remove('ID')\r\n",
    "pred_res = gscv.predict(diabetes_test, key='ID', features=features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.visualizers.model_debriefing import TreeModelDebriefing\r\n",
    "\r\n",
    "shapley_explainer = TreeModelDebriefing.shapley_explainer(pred_res, diabetes_test, key='ID', label='CLASS')\r\n",
    "shapley_explainer.summary_plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unified Report (support model storage)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.model_storage import ModelStorage\r\n",
    "\r\n",
    "model_storage = ModelStorage(connection_context=connection_context)\r\n",
    "gscv.estimator.name = 'HGBT' \r\n",
    "gscv.estimator.version = 1\r\n",
    "model_storage.save_model(model=gscv.estimator)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.visualizers.unified_report import UnifiedReport\r\n",
    "\r\n",
    "mymodel = model_storage.load_model('HGBT', 1)\r\n",
    "\r\n",
    "UnifiedReport(mymodel).build().display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "UnifiedReport(diabetes_test).build().display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Mining Functions\n",
    "\n",
    "cloud version vs on-premise version\n",
    "\n",
    "data from PAL example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "conn_onpremise = ConnectionContext(userkey=\"leiyiyao\")\r\n",
    "conn_cloud = ConnectionContext(userkey=\"raymondyao\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.DataFrame({\"ID\" : ['doc1', 'doc2', 'doc3', 'doc4', 'doc5', 'doc6'],\n",
    "                     \"CONTENT\" : ['term1 term2 term2 term3 term3 term3',\n",
    "                                  'term2 term3 term3 term4 term4 term4',\n",
    "                                  'term3 term4 term4 term5 term5 term5',\n",
    "                                  'term3 term4 term4 term5 term5 term5 term5 term5 term5',\n",
    "                                  'term4 term6',\n",
    "                                  'term4 term6 term6 term6'],\n",
    "                     \"CATEGORY\" : ['CATEGORY_1', 'CATEGORY_1', 'CATEGORY_2', 'CATEGORY_2', 'CATEGORY_3', 'CATEGORY_3']})\n",
    "df_test1 = pd.DataFrame({\"CONTENT\":[\"term2 term2 term3 term3\"]})\n",
    "df_test2 = pd.DataFrame({\"CONTENT\":[\"term3\"]})\n",
    "df_test3 = pd.DataFrame({\"CONTENT\":[\"doc3\"]})\n",
    "df_test4 = pd.DataFrame({\"CONTENT\":[\"term3\"]})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_onpremise = create_dataframe_from_pandas(connection_context=conn_onpremise, pandas_df=data, table_name=\"TM_DEMO\", force=True)\n",
    "df_cloud = create_dataframe_from_pandas(connection_context=conn_cloud, pandas_df=data, table_name=\"TM_DEMO\", force=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TFIDF (cloud only)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.text.tm import tf_analysis\n",
    "\n",
    "tfidf= tf_analysis(df_cloud)\n",
    "tfidf[0].head(3).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### via reference data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.text.tm import text_classification\n",
    "\n",
    "res, stat = text_classification(df_cloud.select(df_cloud.columns[0], df_cloud.columns[1]), df_cloud)\n",
    "res.head(1).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res = text_classification(df_onpremise.select(df_onpremise.columns[0], df_onpremise.columns[1]), df_onpremise)\n",
    "res.head(1).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### via calculated TFIDF (cloud only)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res, stat = text_classification(df_cloud.select(df_cloud.columns[0], df_cloud.columns[1]), tfidf)\n",
    "res.head(1).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from hana_ml.text.tm import get_related_doc, get_related_term, get_relevant_doc, get_relevant_term, get_suggested_term\n",
    "\n",
    "df_test1_cloud = create_dataframe_from_pandas(connection_context=conn_cloud,\n",
    "                                                        pandas_df=df_test1,\n",
    "                                                        table_name=\"#TM_DATA1\",\n",
    "                                                        force=True)\n",
    "\n",
    "df_test2_cloud = create_dataframe_from_pandas(connection_context=conn_cloud,\n",
    "                                                        pandas_df=df_test2,\n",
    "                                                        table_name=\"#TM_DATA2\",\n",
    "                                                        force=True)\n",
    "\n",
    "df_test3_cloud = create_dataframe_from_pandas(connection_context=conn_cloud,\n",
    "                                                        pandas_df=df_test3,\n",
    "                                                        table_name=\"#TM_DATA3\",\n",
    "                                                        force=True)\n",
    "\n",
    "df_test4_cloud = create_dataframe_from_pandas(connection_context=conn_cloud,\n",
    "                                                        pandas_df=df_test4,\n",
    "                                                        table_name=\"#TM_DATA4\",\n",
    "                                                        force=True)\n",
    "df_test1_onpremise = create_dataframe_from_pandas(connection_context=conn_onpremise,\n",
    "                                                    pandas_df=df_test1,\n",
    "                                                    table_name=\"TM_DATA1\",\n",
    "                                                    force=True)\n",
    "\n",
    "df_test2_onpremise = create_dataframe_from_pandas(connection_context=conn_onpremise,\n",
    "                                                    pandas_df=df_test2,\n",
    "                                                    table_name=\"TM_DATA2\",\n",
    "                                                    force=True)\n",
    "\n",
    "df_test3_onpremise = create_dataframe_from_pandas(connection_context=conn_onpremise,\n",
    "                                                    pandas_df=df_test3,\n",
    "                                                    table_name=\"TM_DATA3\",\n",
    "                                                    force=True)\n",
    "\n",
    "df_test4_onpremise = create_dataframe_from_pandas(connection_context=conn_onpremise,\n",
    "                                                    pandas_df=df_test4,\n",
    "                                                    table_name=\"TM_DATA4\",\n",
    "                                                    force=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get related doc"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_related_doc(df_test1_cloud, tfidf).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grd_onpremise = get_related_doc(df_test1_onpremise, df_onpremise)\n",
    "print(grd_onpremise.select_statement)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grd_onpremise.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get related term"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_related_term(df_test2_cloud, df_cloud).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grt_onpremise = get_related_term(df_test2_onpremise, df_onpremise)\n",
    "print(grt_onpremise.select_statement)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grt_onpremise.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get relevant doc"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_relevant_doc(df_test2_cloud, df_cloud).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grvd_onpremise = get_relevant_doc(pred_data=df_test2_onpremise, ref_data=df_onpremise, top=4)\n",
    "print(grvd_onpremise.select_statement)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grvd_onpremise.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get relevant term"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_relevant_term(df_test4_cloud, df_cloud).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grvt_onpremise = get_relevant_term(df_test4_onpremise, df_onpremise)\n",
    "print(grvt_onpremise.select_statement)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grvt_onpremise.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get suggested term"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_suggested_term(df_test4_cloud, df_cloud).collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gst_onpremise = get_suggested_term(df_test4_onpremise, df_onpremise)\n",
    "print(gst_onpremise.select_statement)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gst_onpremise.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "9e8e26eb492012ce43ec3ea98c3fc2503d5495ecd40107dd94395e1e0d860e85"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}