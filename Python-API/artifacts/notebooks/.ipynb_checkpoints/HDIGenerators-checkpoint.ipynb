{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Requirements\n",
    "\n",
    "Let's import the necessary libraries for our use case. In here there is yaml for configuration management, a machine learning algorithm, a dataframe for data manipulation as well as the artifact generator and deployer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I308290\\Miniconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from hana_ml.algorithms.pal.unified_classification import UnifiedClassification\n",
    "import hana_ml.dataframe as dataframe\n",
    "\n",
    "from hana_ml.artifacts.generators import hana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create connection context\n",
    "\n",
    "In the following code block we just load our credentials from disk in order to not leak them into this notebook or the underlying git repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.utility import DataSets, Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import configparser\n",
    "except ImportError:\n",
    "    import ConfigParser as configparser\n",
    "Settings.settings = configparser.ConfigParser()\n",
    "Settings.settings.read(\"../../config/e2edata.ini\")\n",
    "url = Settings.settings.get(\"hana\", \"url\")\n",
    "port = Settings.settings.get(\"hana\", \"port\")\n",
    "user = Settings.settings.get(\"hana\", \"user\")\n",
    "passwd = Settings.settings.get(\"hana\", \"passwd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to create a connection context for our HANA system. This allows us to access the required data, as well as the PAL procedures we need to call in order to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_context = dataframe.ConnectionContext(\n",
    "    url, int(port), user, passwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.50.000.00.1663300048 (master)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection_context.hana_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAL_TEST'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection_context.get_current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also enable SQL tracing for later reuse of the model in the deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare the data\n",
    "\n",
    "This block is part of the utils for this demo - it makes sure the dataset is in the system and creates it if necessary. In a real production use case this would obviously be unnecessary since the data is already in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table PIMA_INDIANS_DIABETES_TBL exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "diabetes_full, diabetes_train_valid, diabetes_test, _ = DataSets.load_diabetes_data(connection_context)\n",
    "diabetes_train_valid = diabetes_train_valid.save(\"diabetes_train_valid\")\n",
    "diabetes_test = diabetes_test.save(\"diabetes_test\")\n",
    "Settings.set_log_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_context.sql_tracer.enable_sql_trace(True)\n",
    "connection_context.sql_tracer.enable_trace_history(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Science Loop\n",
    "\n",
    "In this section the real work of a data scientist happens. They manipulate the data, preprocess columns, choose a model and try different combinations of hyper parameters.\n",
    "\n",
    "Since we just want to demonstrate the deployment, lets keep this short and just use a basic Random Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hana_ml.ml_base:Executing SQL: DO\n",
      "BEGIN\n",
      "DECLARE param_name VARCHAR(5000) ARRAY;\n",
      "DECLARE int_value INTEGER ARRAY;\n",
      "DECLARE double_value DOUBLE ARRAY;\n",
      "DECLARE string_value VARCHAR(5000) ARRAY;\n",
      "param_name[1] := N'FUNCTION';\n",
      "int_value[1] := NULL;\n",
      "double_value[1] := NULL;\n",
      "string_value[1] := N'RDT';\n",
      "param_name[2] := N'KEY';\n",
      "int_value[2] := 1;\n",
      "double_value[2] := NULL;\n",
      "string_value[2] := NULL;\n",
      "param_name[3] := N'N_ESTIMATORS';\n",
      "int_value[3] := 5;\n",
      "double_value[3] := NULL;\n",
      "string_value[3] := NULL;\n",
      "param_name[4] := N'SPLIT_THRESHOLD';\n",
      "int_value[4] := NULL;\n",
      "double_value[4] := 0;\n",
      "string_value[4] := NULL;\n",
      "param_name[5] := N'MAX_DEPTH';\n",
      "int_value[5] := 10;\n",
      "double_value[5] := NULL;\n",
      "string_value[5] := NULL;\n",
      "param_name[6] := N'PARTITION_METHOD';\n",
      "int_value[6] := 2;\n",
      "double_value[6] := NULL;\n",
      "string_value[6] := NULL;\n",
      "param_name[7] := N'PARTITION_STRATIFIED_VARIABLE';\n",
      "int_value[7] := NULL;\n",
      "double_value[7] := NULL;\n",
      "string_value[7] := N'CLASS';\n",
      "param_name[8] := N'HANDLE_MISSING_VALUE';\n",
      "int_value[8] := 0;\n",
      "double_value[8] := NULL;\n",
      "string_value[8] := NULL;\n",
      "param_name[9] := N'CATEGORICAL_VARIABLE';\n",
      "int_value[9] := NULL;\n",
      "double_value[9] := NULL;\n",
      "string_value[9] := N'CLASS';\n",
      "params = UNNEST(:param_name, :int_value, :double_value, :string_value);\n",
      "in_0 = SELECT \"ID\", \"PREGNANCIES\", \"GLUCOSE\", \"SKINTHICKNESS\", \"INSULIN\", \"BMI\", \"AGE\", \"CLASS\" FROM (SELECT * FROM \"diabetes_train_valid\") AS \"DT_12\";\n",
      "CALL _SYS_AFL.PAL_UNIFIED_CLASSIFICATION(:in_0, :params, out_0, out_1, out_2, out_3, out_4, out_5, out_6, out_7);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_MODEL_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_0);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_IMPORTANCE_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_1);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_STATS_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_2);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_OPT_PARAM_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_3);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_CONFUSION_MATRIX_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_4);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_METRICS_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_5);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_PARTITION_TYPE_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_6);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIFICATION_PLACE_HOLDER1_0_59205937_451B_11ED_AE14_F47B099F40D8\" AS (SELECT * FROM :out_7);\n",
      "END\n",
      "\n",
      "INFO:hana_ml.ml_base:Executing SQL: DO (IN in_1 TABLE (\"ROW_INDEX\" INT, \"PART_INDEX\" INT, \"MODEL_CONTENT\" NCLOB) => \"#PAL_UNIFIED_CLASSIFICATION_MODEL_0_59205937_451B_11ED_AE14_F47B099F40D8\")\n",
      "BEGIN\n",
      "DECLARE param_name VARCHAR(5000) ARRAY;\n",
      "DECLARE int_value INTEGER ARRAY;\n",
      "DECLARE double_value DOUBLE ARRAY;\n",
      "DECLARE string_value VARCHAR(5000) ARRAY;\n",
      "param_name[1] := N'FUNCTION';\n",
      "int_value[1] := NULL;\n",
      "double_value[1] := NULL;\n",
      "string_value[1] := N'RDT';\n",
      "param_name[2] := N'HANDLE_MISSING_VALUE';\n",
      "int_value[2] := 0;\n",
      "double_value[2] := NULL;\n",
      "string_value[2] := NULL;\n",
      "params = UNNEST(:param_name, :int_value, :double_value, :string_value);\n",
      "in_0 = SELECT \"ID\", \"PREGNANCIES\", \"GLUCOSE\", \"SKINTHICKNESS\", \"INSULIN\", \"BMI\", \"AGE\" FROM (SELECT \"ID\", \"PREGNANCIES\", \"GLUCOSE\", \"SKINTHICKNESS\", \"INSULIN\", \"BMI\", \"AGE\" FROM (SELECT * FROM \"diabetes_test\") AS \"DT_16\") AS \"DT_33\";\n",
      "CALL _SYS_AFL.PAL_UNIFIED_CLASSIFICATION_PREDICT(:in_0, :in_1, :params, out_0, out_1);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIF_PREDICT_RESULT_TBL_0_5DF0523B_451B_11ED_BC75_F47B099F40D8\" AS (SELECT * FROM :out_0);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_UNIFIED_CLASSIF_PREDICT_PH_TBL_0_5DF0523B_451B_11ED_BC75_F47B099F40D8\" AS (SELECT * FROM :out_1);\n",
      "END\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hana_ml.dataframe.DataFrame at 0x1d1e3bef400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rfc_params = dict(n_estimators=5, split_threshold=0, max_depth=10)\n",
    "rfc = UnifiedClassification(func=\"RandomDecisionTree\", **rfc_params)\n",
    "rfc.fit(diabetes_train_valid, \n",
    "        key='ID', \n",
    "        label='CLASS', \n",
    "        categorical_variable=['CLASS'],\n",
    "        partition_method='stratified',\n",
    "        stratified_column='CLASS',)\n",
    "cm = rfc.confusion_matrix_.collect()\n",
    "rfc.predict(diabetes_test.drop(cols=['CLASS']), key=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the confusion matrix and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "print(float(cm['COUNT'][cm['ACTUAL_CLASS'] == cm['PREDICTED_CLASS']].sum()) / cm['COUNT'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate HDI artifact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = hana.HanaGenerator(project_name=\"test\", version='1', grant_service='', connection_context=connection_context, outputdir=\".\\\\test_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg.config.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg.generate_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
